{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import torch.optim\n",
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "import nnts\n",
                "import nnts.data\n",
                "from nnts import utils\n",
                "import nnts.torch.models\n",
                "import nnts.torch.trainers\n",
                "import nnts.metrics\n",
                "import nnts.torch.datasets\n",
                "import nnts.torch.utils\n",
                "import nnts.loggers\n",
                "from nnts import datasets\n",
                "torch.set_printoptions(precision=8, sci_mode=False)\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = \"data\"\n",
                "model_name = \"\"\n",
                "dataset_name = \"ETTh1\"\n",
                "results_path = \"nb-results\"\n",
                "metadata_path = \"informer.json\"\n",
                "\n",
                "metadata = datasets.load_metadata(dataset_name, path=metadata_path)\n",
                "datafile_path = os.path.join(data_path, metadata.filename)\n",
                "PATH = os.path.join(results_path, model_name, metadata.dataset)\n",
                "df = pd.read_csv(datafile_path)\n",
                "utils.makedirs_if_not_exists(PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = utils.Hyperparams(\n",
                "    optimizer=torch.optim.Adam,\n",
                "    loss_fn=torch.nn.L1Loss(),\n",
                "    batch_size=32,\n",
                "    batches_per_epoch=50,\n",
                "    training_method=utils.TrainingMethod.DMS,\n",
                "    model_file_path=\"logs\",\n",
                "    epochs=100,\n",
                "    scheduler=utils.Scheduler.REDUCE_LR_ON_PLATEAU,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>ds</th>\n",
                            "      <th>unique_id</th>\n",
                            "      <th>y</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2016-07-01 00:00:00</td>\n",
                            "      <td>HUFL</td>\n",
                            "      <td>5.827</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2016-07-01 01:00:00</td>\n",
                            "      <td>HUFL</td>\n",
                            "      <td>5.693</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2016-07-01 02:00:00</td>\n",
                            "      <td>HUFL</td>\n",
                            "      <td>5.157</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2016-07-01 03:00:00</td>\n",
                            "      <td>HUFL</td>\n",
                            "      <td>5.090</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2016-07-01 04:00:00</td>\n",
                            "      <td>HUFL</td>\n",
                            "      <td>5.358</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                    ds unique_id      y\n",
                            "0  2016-07-01 00:00:00      HUFL  5.827\n",
                            "1  2016-07-01 01:00:00      HUFL  5.693\n",
                            "2  2016-07-01 02:00:00      HUFL  5.157\n",
                            "3  2016-07-01 03:00:00      HUFL  5.090\n",
                            "4  2016-07-01 04:00:00      HUFL  5.358"
                        ]
                    },
                    "execution_count": 70,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.melt(df, id_vars=[\"date\"], value_vars=[\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"], var_name=\"unique_id\", value_name=\"y\")\n",
                "df = df.rename({\"date\": \"ds\"}, axis=\"columns\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(121940, 3)"
                        ]
                    },
                    "execution_count": 71,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.rename({\"OT\": \"y\", \"date\": \"ds\"}, axis=\"columns\")\n",
                "df[\"unique_id\"] = \"T1\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [],
            "source": [
                "# split lengths as per informer\n",
                "trn_length = int(24 * 365.25)\n",
                "val_test_length = int(24 * 365.25 * (4 / 12))\n",
                "split_data = datasets.split_test_val_train(\n",
                "    df, trn_length, val_test_length, val_test_length\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/garethdavies/Development/workspaces/nnts/nnts/torch/preprocessing.py:63: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  data[numeric_cols] = (numeric_data - self.mean) / self.std\n"
                    ]
                }
            ],
            "source": [
                "nnts.torch.utils.seed_everything(42)\n",
                "dataset_options = {\n",
                "    \"context_length\": metadata.context_length,\n",
                "    \"prediction_length\": metadata.prediction_length,\n",
                "    \"conts\": [],\n",
                "}\n",
                "\n",
                "trn_dl, val_dl, test_dl = nnts.torch.utils.create_dataloaders_from_split_data(\n",
                "    split_data,\n",
                "    Dataset=nnts.torch.datasets.TimeseriesDataset,\n",
                "    dataset_options=dataset_options,\n",
                "    Sampler=nnts.torch.datasets.TimeSeriesSampler,\n",
                "    batch_size=params.batch_size,\n",
                "    transforms = [nnts.torch.preprocessing.StandardScaler()]\n",
                ")\n",
                "\n",
                "net = nnts.torch.models.DLinear(metadata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([7, 2922, 1])"
                        ]
                    },
                    "execution_count": 74,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "val_dl.dataset.X.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DLinear(\n",
                        "  (decompsition): series_decomp(\n",
                        "    (moving_avg): moving_avg(\n",
                        "      (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
                        "    )\n",
                        "  )\n",
                        "  (Linear_Seasonal): ModuleList(\n",
                        "    (0): Linear(in_features=336, out_features=336, bias=True)\n",
                        "  )\n",
                        "  (Linear_Trend): ModuleList(\n",
                        "    (0): Linear(in_features=336, out_features=336, bias=True)\n",
                        "  )\n",
                        "  (Linear_Decoder): ModuleList(\n",
                        "    (0): Linear(in_features=336, out_features=336, bias=True)\n",
                        "  )\n",
                        ")\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n"
                    ]
                }
            ],
            "source": [
                "trner = nnts.torch.trainers.ValidationTorchEpochTrainer(net, params, metadata)\n",
                "evaluator = trner.train(trn_dl, val_dl)\n",
                "y_hat, y = evaluator.evaluate(\n",
                "    test_dl, metadata.prediction_length, metadata.context_length\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.08667834793503548"
                        ]
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "0.29441186785697937 **2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(torch.Size([15757, 336, 1]), torch.Size([15757, 336, 1]))"
                        ]
                    },
                    "execution_count": 65,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_hat.shape, y.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[0.32819790],\n",
                            "        [0.11649176],\n",
                            "        [0.28753734],\n",
                            "        [0.09909239],\n",
                            "        [0.10163941],\n",
                            "        [0.03509720],\n",
                            "        [0.35242835]])"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "The size of tensor a (15757) must match the size of tensor b (7) at non-singleton dimension 0",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mnnts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_seasonal_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseasonality\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_metrics\n",
                        "File \u001b[0;32m~/Development/workspaces/nnts/nnts/metrics.py:473\u001b[0m, in \u001b[0;36mcalc_metrics\u001b[0;34m(y_hat, y, seasonal_error)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_metrics\u001b[39m(\n\u001b[1;32m    471\u001b[0m     y_hat: torch\u001b[38;5;241m.\u001b[39mtensor, y: torch\u001b[38;5;241m.\u001b[39mtensor, seasonal_error: torch\u001b[38;5;241m.\u001b[39mtensor\n\u001b[1;32m    472\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m--> 473\u001b[0m     metrics_per_ts \u001b[38;5;241m=\u001b[39m \u001b[43mget_metrics_per_ts\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m     base_metrics \u001b[38;5;241m=\u001b[39m aggregate_base_metrics(metrics_per_ts)\n\u001b[1;32m    475\u001b[0m     mean_metrics \u001b[38;5;241m=\u001b[39m aggregate_mean_metrics(metrics_per_ts)\n",
                        "File \u001b[0;32m~/Development/workspaces/nnts/nnts/metrics.py:403\u001b[0m, in \u001b[0;36mget_metrics_per_ts\u001b[0;34m(y_hat, y, seasonal_error)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_metrics_per_ts\u001b[39m(\n\u001b[1;32m    401\u001b[0m     y_hat: torch\u001b[38;5;241m.\u001b[39mtensor, y: torch\u001b[38;5;241m.\u001b[39mtensor, seasonal_error: torch\u001b[38;5;241m.\u001b[39mtensor\n\u001b[1;32m    402\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor]:\n\u001b[0;32m--> 403\u001b[0m     mase_per_ts \u001b[38;5;241m=\u001b[39m \u001b[43mmase\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     mase_per_ts \u001b[38;5;241m=\u001b[39m mase_per_ts[mase_per_ts\u001b[38;5;241m.\u001b[39misfinite()]\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mse(y_hat, y),\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabs_error\u001b[39m\u001b[38;5;124m\"\u001b[39m: abs_error(y_hat, y),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseasonal_error\u001b[39m\u001b[38;5;124m\"\u001b[39m: seasonal_error,\n\u001b[1;32m    418\u001b[0m     }\n",
                        "File \u001b[0;32m~/Development/workspaces/nnts/nnts/metrics.py:266\u001b[0m, in \u001b[0;36mmase\u001b[0;34m(y_hat, y, seasonal_errors, dim)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmase\u001b[39m(\n\u001b[1;32m    229\u001b[0m     y_hat: torch\u001b[38;5;241m.\u001b[39mtensor,\n\u001b[1;32m    230\u001b[0m     y: torch\u001b[38;5;241m.\u001b[39mtensor,\n\u001b[1;32m    231\u001b[0m     seasonal_errors: torch\u001b[38;5;241m.\u001b[39mtensor,\n\u001b[1;32m    232\u001b[0m     dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    233\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor:\n\u001b[1;32m    234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Calculates the Mean Absolute Scaled Error (MASE) between the predicted values and the actual values.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    tensor([1.25])\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmae\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseasonal_errors\u001b[49m\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15757) must match the size of tensor b (7) at non-singleton dimension 0"
                    ]
                }
            ],
            "source": [
                "\n",
                "test_metrics = nnts.metrics.calc_metrics(\n",
                "    y_hat, y, nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)\n",
                ")\n",
                "test_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.09299259328599963"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "0.3049468696117401**2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nnts.metrics.calc_metrics(y_hat[:, :1, :], y[:, :1, :], nnts.metrics.calculate_seasonal_error(trn_dl, metadata))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_results(y_hat, y, name):\n",
                "    torch.save(y_hat, f\"{PATH}/{name}_y_hat.pt\")\n",
                "    torch.save(y, f\"{PATH}/{name}_y.pt\")\n",
                "save_results(y_hat, y, scenario.name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "covariate_name = f\"cov-1-pearsn-0.68-pl-{str(scenario.prediction_length)}-seed-{scenario.seed}\"\n",
                "covariate_y_hat = torch.load(f\"{PATH}/{covariate_name}_y_hat.pt\")\n",
                "covariate_y = torch.load(f\"{PATH}/{covariate_name}_y.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_forecast_horizon_metrics(y_hat, y, metadata, metric=\"mae\"):\n",
                "    forecast_horizon_metrics = []\n",
                "    for i in range(1, metadata.prediction_length):\n",
                "        metrics = nnts.metrics.calc_metrics(y[:, :i, :], y_hat[:, :i, :], metadata.freq, metadata.seasonality)\n",
                "        forecast_horizon_metrics.append(metrics[metric])\n",
                "    return forecast_horizon_metrics\n",
                "\n",
                "forecast_horizon_metrics = calculate_forecast_horizon_metrics(y_hat, y, metadata, \"mae\")\n",
                "covariate_forecast_horizon_metrics = calculate_forecast_horizon_metrics(covariate_y_hat, covariate_y, metadata, \"mae\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "sns.set()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(forecast_horizon_metrics, label='univariate')\n",
                "plt.plot(covariate_forecast_horizon_metrics, label='covariate (0.68)')\n",
                "plt.xlabel(\"Forecast Horizon\")\n",
                "plt.ylabel(\"Error (MAE)\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_aggregator = nnts.datasets.CSVFileAggregator(PATH, \"results\")\n",
                "results = csv_aggregator()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.tail(metadata.prediction_length*50)['y'].plot()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_hat_last = y_hat[:, :1, ...]\n",
                "y_last = y[:, :1, ...]\n",
                "df_test = df.tail(y_hat_last.shape[0])\n",
                "df_test[\"y_check\"] = y_last.squeeze()\n",
                "df_test[\"y_hat\"] = y_hat_last.squeeze()\n",
                "df_test[[\"y\", \"y_check\", \"y_hat\"]]\n",
                "df_test.set_index(\"ds\")[[\"y_check\", \"y_hat\"]].iloc[4500:4500+336].plot(figsize=(20, 10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_metrics = nnts.metrics.calc_metrics(y_last, y_hat_last, metadata.freq, metadata.seasonality)\n",
                "test_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
