{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import nnts\n",
    "import nnts.data\n",
    "from nnts import utils\n",
    "import nnts.torch.models\n",
    "import nnts.torch.trainers\n",
    "import nnts.metrics\n",
    "import nnts.torch.datasets\n",
    "import nnts.torch.utils\n",
    "import nnts.loggers\n",
    "from nnts import datasets\n",
    "torch.set_printoptions(precision=8, sci_mode=False)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "model_name = \"\"\n",
    "dataset_name = \"ETTh2\"\n",
    "results_path = \"nb-results\"\n",
    "metadata_path = \"informer.json\"\n",
    "\n",
    "metadata = datasets.load_metadata(dataset_name, path=metadata_path)\n",
    "datafile_path = os.path.join(data_path, metadata.filename)\n",
    "PATH = os.path.join(results_path, model_name, metadata.dataset)\n",
    "df = pd.read_csv(datafile_path)\n",
    "utils.makedirs_if_not_exists(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = utils.Hyperparams(\n",
    "    optimizer=torch.optim.Adam,\n",
    "    loss_fn=torch.nn.L1Loss(),\n",
    "    batch_size=32,\n",
    "    batches_per_epoch=50,\n",
    "    training_method=utils.TrainingMethod.DMS,\n",
    "    model_file_path=\"logs\",\n",
    "    epochs=100,\n",
    "    scheduler=utils.Scheduler.REDUCE_LR_ON_PLATEAU,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "      <td>HUFL</td>\n",
       "      <td>41.130001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01 01:00:00</td>\n",
       "      <td>HUFL</td>\n",
       "      <td>37.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01 02:00:00</td>\n",
       "      <td>HUFL</td>\n",
       "      <td>37.946999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01 03:00:00</td>\n",
       "      <td>HUFL</td>\n",
       "      <td>38.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01 04:00:00</td>\n",
       "      <td>HUFL</td>\n",
       "      <td>38.113998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ds unique_id          y\n",
       "0  2016-07-01 00:00:00      HUFL  41.130001\n",
       "1  2016-07-01 01:00:00      HUFL  37.528000\n",
       "2  2016-07-01 02:00:00      HUFL  37.946999\n",
       "3  2016-07-01 03:00:00      HUFL  38.952000\n",
       "4  2016-07-01 04:00:00      HUFL  38.113998"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ONLY RUN FOR UNIVARIATE\n",
    "df = pd.melt(df, id_vars=[\"date\"], value_vars=[\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"], var_name=\"unique_id\", value_name=\"y\")\n",
    "df = df.rename({\"date\": \"ds\"}, axis=\"columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>HUFL</th>\n",
       "      <th>HULL</th>\n",
       "      <th>MUFL</th>\n",
       "      <th>MULL</th>\n",
       "      <th>LUFL</th>\n",
       "      <th>LULL</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17415</th>\n",
       "      <td>2018-06-26 15:00:00</td>\n",
       "      <td>39.202999</td>\n",
       "      <td>11.392</td>\n",
       "      <td>49.644001</td>\n",
       "      <td>11.929</td>\n",
       "      <td>-10.331</td>\n",
       "      <td>-1.258</td>\n",
       "      <td>47.084999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17416</th>\n",
       "      <td>2018-06-26 16:00:00</td>\n",
       "      <td>38.113998</td>\n",
       "      <td>10.974</td>\n",
       "      <td>48.759998</td>\n",
       "      <td>11.366</td>\n",
       "      <td>-10.331</td>\n",
       "      <td>-1.290</td>\n",
       "      <td>48.183498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17417</th>\n",
       "      <td>2018-06-26 17:00:00</td>\n",
       "      <td>39.622002</td>\n",
       "      <td>10.974</td>\n",
       "      <td>50.609001</td>\n",
       "      <td>11.661</td>\n",
       "      <td>-11.557</td>\n",
       "      <td>-1.418</td>\n",
       "      <td>48.183498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17418</th>\n",
       "      <td>2018-06-26 18:00:00</td>\n",
       "      <td>43.643002</td>\n",
       "      <td>13.403</td>\n",
       "      <td>54.737000</td>\n",
       "      <td>13.778</td>\n",
       "      <td>-10.299</td>\n",
       "      <td>-1.418</td>\n",
       "      <td>46.865501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17419</th>\n",
       "      <td>2018-06-26 19:00:00</td>\n",
       "      <td>38.868000</td>\n",
       "      <td>10.052</td>\n",
       "      <td>49.859001</td>\n",
       "      <td>10.669</td>\n",
       "      <td>-11.525</td>\n",
       "      <td>-1.418</td>\n",
       "      <td>45.986500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date       HUFL    HULL       MUFL    MULL    LUFL  \\\n",
       "17415  2018-06-26 15:00:00  39.202999  11.392  49.644001  11.929 -10.331   \n",
       "17416  2018-06-26 16:00:00  38.113998  10.974  48.759998  11.366 -10.331   \n",
       "17417  2018-06-26 17:00:00  39.622002  10.974  50.609001  11.661 -11.557   \n",
       "17418  2018-06-26 18:00:00  43.643002  13.403  54.737000  13.778 -10.299   \n",
       "17419  2018-06-26 19:00:00  38.868000  10.052  49.859001  10.669 -11.525   \n",
       "\n",
       "        LULL         OT  \n",
       "17415 -1.258  47.084999  \n",
       "17416 -1.290  48.183498  \n",
       "17417 -1.418  48.183498  \n",
       "17418 -1.418  46.865501  \n",
       "17419 -1.418  45.986500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"OT\": \"y\", \"date\": \"ds\"}, axis=\"columns\")\n",
    "df[\"unique_id\"] = \"T1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ds', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'y', 'unique_id'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split lengths as per informer\n",
    "trn_length = int(24 * 365.25)\n",
    "val_test_length = int(24 * 365.25 * (4 / 12))\n",
    "split_data = datasets.split_test_val_train(\n",
    "    df, trn_length, val_test_length, val_test_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nnts.torch.models' has no attribute 'dLinear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# net = nnts.torch.models.TSMixer(metadata.context_length, metadata.prediction_length,7,7, num_blocks=4, ff_dim=256, dropout_rate=0.9)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnnts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdlinear\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mnnts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdLinear\u001b[49m\u001b[38;5;241m.\u001b[39mget_mutlivariate_params()\n\u001b[1;32m     28\u001b[0m net \u001b[38;5;241m=\u001b[39m nnts\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mDLinear(\n\u001b[1;32m     29\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mprediction_length,\n\u001b[1;32m     30\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mcontext_length,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;241m7\u001b[39m,\n\u001b[1;32m     32\u001b[0m     params\n\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nnts.torch.models' has no attribute 'dLinear'"
     ]
    }
   ],
   "source": [
    "nnts.torch.utils.seed_everything(42)\n",
    "dataset_options = {\n",
    "    \"context_length\": metadata.context_length,\n",
    "    \"prediction_length\": metadata.prediction_length,\n",
    "    \"conts\": [\n",
    "        \"HUFL\",\n",
    "        \"HULL\",\n",
    "        \"MUFL\",\n",
    "        \"MULL\",\n",
    "        \"LUFL\",\n",
    "        \"LULL\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "trn_dl, val_dl, test_dl = nnts.torch.utils.create_dataloaders_from_split_data(\n",
    "    split_data,\n",
    "    Dataset=nnts.torch.datasets.TimeseriesDataset,\n",
    "    dataset_options=dataset_options,\n",
    "    Sampler=nnts.torch.datasets.TimeSeriesSampler,\n",
    "    batch_size=params.batch_size,\n",
    "    transforms = [nnts.torch.preprocessing.StandardScaler()]\n",
    ")\n",
    "\n",
    "# net = nnts.torch.models.TSMixer(metadata.context_length, metadata.prediction_length,7,7, num_blocks=4, ff_dim=256, dropout_rate=0.9)\n",
    "import nnts.torch.models.dlinear\n",
    "params = nnts.torch.models.dlinear.get_mutlivariate_params()\n",
    "\n",
    "net = nnts.torch.models.DLinear(\n",
    "    metadata.prediction_length,\n",
    "    metadata.context_length,\n",
    "    7,\n",
    "    params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2922, 7])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dl.dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSMixer(\n",
      "  (mixer_layers): Sequential(\n",
      "    (0): MixerLayer(\n",
      "      (time_mixing): TimeMixing(\n",
      "        (norm): TimeBatchNorm2d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout): Dropout(p=0.9, inplace=False)\n",
      "        (fc1): Linear(in_features=336, out_features=336, bias=True)\n",
      "      )\n",
      "      (feature_mixing): FeatureMixing(\n",
      "        (norm_before): TimeBatchNorm2d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm_after): Identity()\n",
      "        (dropout): Dropout(p=0.9, inplace=False)\n",
      "        (fc1): Linear(in_features=7, out_features=256, bias=True)\n",
      "        (fc2): Linear(in_features=256, out_features=7, bias=True)\n",
      "        (projection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): MixerLayer(\n",
      "      (time_mixing): TimeMixing(\n",
      "        (norm): TimeBatchNorm2d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout): Dropout(p=0.9, inplace=False)\n",
      "        (fc1): Linear(in_features=336, out_features=336, bias=True)\n",
      "      )\n",
      "      (feature_mixing): FeatureMixing(\n",
      "        (norm_before): TimeBatchNorm2d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm_after): Identity()\n",
      "        (dropout): Dropout(p=0.9, inplace=False)\n",
      "        (fc1): Linear(in_features=7, out_features=256, bias=True)\n",
      "        (fc2): Linear(in_features=256, out_features=7, bias=True)\n",
      "        (projection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): MixerLayer(\n",
      "      (time_mixing): TimeMixing(\n",
      "        (norm): TimeBatchNorm2d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (dropout): Dropout(p=0.9, inplace=False)\n",
      "        (fc1): Linear(in_features=336, out_features=336, bias=True)\n",
      "      )\n",
      "      (feature_mixing): FeatureMixing(\n",
      "        (norm_before): TimeBatchNorm2d(2352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm_after): Identity()\n",
      "        (dropout): Dropout(p=0.9, inplace=False)\n",
      "        (fc1): Linear(in_features=7, out_features=256, bias=True)\n",
      "        (fc2): Linear(in_features=256, out_features=7, bias=True)\n",
      "        (projection): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (temporal_projection): Linear(in_features=336, out_features=336, bias=True)\n",
      ")\n",
      "Epoch 1 Train Loss: 0.9655070304870605  Valid Loss: 0.8504951000213623\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 2 Train Loss: 0.6199838519096375  Valid Loss: 0.7832266688346863\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 4 Train Loss: 0.5233713388442993  Valid Loss: 0.7706356644630432\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 5 Train Loss: 0.5245462656021118  Valid Loss: 0.7632304430007935\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 8 Train Loss: 0.5019277930259705  Valid Loss: 0.7448264360427856\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 22 Train Loss: 0.4798288345336914  Valid Loss: 0.7418441772460938\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 23 Train Loss: 0.46745193004608154  Valid Loss: 0.7357526421546936\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 24 Train Loss: 0.4680732786655426  Valid Loss: 0.724127471446991\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 28 Train Loss: 0.4759969711303711  Valid Loss: 0.7219033241271973\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 40 Train Loss: 0.4605158269405365  Valid Loss: 0.7115220427513123\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 41 Train Loss: 0.4631294012069702  Valid Loss: 0.7025483250617981\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 43 Train Loss: 0.46281445026397705  Valid Loss: 0.6977388858795166\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 47 Train Loss: 0.4639718234539032  Valid Loss: 0.6964982748031616\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 49 Train Loss: 0.44882479310035706  Valid Loss: 0.6958525776863098\n",
      "saving model to logs/best_model.pt\n",
      "Epoch 66 Train Loss: 0.45658808946609497  Valid Loss: 0.6947128176689148\n",
      "saving model to logs/best_model.pt\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "trner = nnts.torch.trainers.ValidationTorchEpochTrainer(net, params, metadata)\n",
    "evaluator = trner.train(trn_dl, val_dl)\n",
    "y_hat, y = evaluator.evaluate(\n",
    "    test_dl, metadata.prediction_length, metadata.context_length\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2251, 336, 7]), torch.Size([2251, 336, 7]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.26181477]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 2.187605619430542,\n",
       " 'abs_error': 5776184.0,\n",
       " 'abs_target_sum': 7172264.0,\n",
       " 'abs_target_mean': 1.3547011613845825,\n",
       " 'seasonal_error': 0.26181477308273315,\n",
       " 'mean_mase': 4.1671013832092285,\n",
       " 'mean_mape': 1.209301471710205,\n",
       " 'mean_smape': 1.298594355583191,\n",
       " 'mean_msmape': 1.0205368995666504,\n",
       " 'mean_mae': 1.0910087823867798,\n",
       " 'mean_rmse': 1.192393183708191,\n",
       " 'median_mase': 3.2347700595855713,\n",
       " 'median_smape': 1.339519739151001,\n",
       " 'median_msmape': 1.0308233499526978,\n",
       " 'median_mae': 0.8469105958938599,\n",
       " 'median_rmse': 0.9646993279457092}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_metrics = nnts.metrics.calc_metrics(\n",
    "    y_hat, y, nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)\n",
    ")\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09299259328599963"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3049468696117401**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnts.metrics.calc_metrics(y_hat[:, :1, :], y[:, :1, :], nnts.metrics.calculate_seasonal_error(trn_dl, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(y_hat, y, name):\n",
    "    torch.save(y_hat, f\"{PATH}/{name}_y_hat.pt\")\n",
    "    torch.save(y, f\"{PATH}/{name}_y.pt\")\n",
    "save_results(y_hat, y, scenario.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_name = f\"cov-1-pearsn-0.68-pl-{str(scenario.prediction_length)}-seed-{scenario.seed}\"\n",
    "covariate_y_hat = torch.load(f\"{PATH}/{covariate_name}_y_hat.pt\")\n",
    "covariate_y = torch.load(f\"{PATH}/{covariate_name}_y.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecast_horizon_metrics(y_hat, y, metadata, metric=\"mae\"):\n",
    "    forecast_horizon_metrics = []\n",
    "    for i in range(1, metadata.prediction_length):\n",
    "        metrics = nnts.metrics.calc_metrics(y[:, :i, :], y_hat[:, :i, :], metadata.freq, metadata.seasonality)\n",
    "        forecast_horizon_metrics.append(metrics[metric])\n",
    "    return forecast_horizon_metrics\n",
    "\n",
    "forecast_horizon_metrics = calculate_forecast_horizon_metrics(y_hat, y, metadata, \"mae\")\n",
    "covariate_forecast_horizon_metrics = calculate_forecast_horizon_metrics(covariate_y_hat, covariate_y, metadata, \"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(forecast_horizon_metrics, label='univariate')\n",
    "plt.plot(covariate_forecast_horizon_metrics, label='covariate (0.68)')\n",
    "plt.xlabel(\"Forecast Horizon\")\n",
    "plt.ylabel(\"Error (MAE)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_aggregator = nnts.datasets.CSVFileAggregator(PATH, \"results\")\n",
    "results = csv_aggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(metadata.prediction_length*50)['y'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_last = y_hat[:, :1, ...]\n",
    "y_last = y[:, :1, ...]\n",
    "df_test = df.tail(y_hat_last.shape[0])\n",
    "df_test[\"y_check\"] = y_last.squeeze()\n",
    "df_test[\"y_hat\"] = y_hat_last.squeeze()\n",
    "df_test[[\"y\", \"y_check\", \"y_hat\"]]\n",
    "df_test.set_index(\"ds\")[[\"y_check\", \"y_hat\"]].iloc[4500:4500+336].plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = nnts.metrics.calc_metrics(y_last, y_hat_last, metadata.freq, metadata.seasonality)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnts-uwGNJDPB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
