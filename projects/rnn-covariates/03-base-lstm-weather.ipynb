{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "import nnts\n",
    "import nnts.data\n",
    "import nnts.experiments\n",
    "import nnts.models\n",
    "import nnts.torch.data.preprocessing as preprocessing\n",
    "import nnts.torch.models\n",
    "import nnts.torch.models.trainers as trainers\n",
    "import nnts.metrics\n",
    "import nnts.torch.data\n",
    "import nnts.torch.data.datasets\n",
    "import nnts.loggers\n",
    "import covs \n",
    "import scipy\n",
    "import os\n",
    "import nnts.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "model_name = \"seg-lstm\"\n",
    "dataset_name = \"weather\"\n",
    "results_path = \"nb-results\"\n",
    "metadata_path = os.path.join(data_path, f\"informer.json\")\n",
    "metadata = nnts.data.metadata.load(dataset_name, path=metadata_path)\n",
    "datafile_path = os.path.join(data_path, metadata.filename)\n",
    "PATH = os.path.join(results_path, model_name, metadata.dataset)\n",
    "\n",
    "df_orig = pd.read_csv(datafile_path)\n",
    "params = nnts.models.Hyperparams()\n",
    "splitter = nnts.pandas.FixedSizeSplitter()\n",
    "\n",
    "nnts.loggers.makedirs_if_not_exists(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig.rename({\"WetBulbCelsius\": \"y\", \"date\": \"ds\"}, axis=\"columns\")\n",
    "df_orig[\"unique_id\"] = \"T1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print correlation with target\n",
    "cols = df_orig.columns.tolist()\n",
    "cols.remove(\"ds\")\n",
    "cols.remove(\"unique_id\")\n",
    "cols.remove(\"y\")\n",
    "for i in range(len(cols)):\n",
    "    pearson = scipy.stats.pearsonr(df_orig[\"y\"], df_orig[cols[i]])\n",
    "    print(cols[i], pearson[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation with various leads\n",
    "pearson_list = []\n",
    "for i in range(192):\n",
    "    pearson = scipy.stats.pearsonr(\n",
    "        df_orig[\"y\"], df_orig.shift(i).bfill()[\"StationPressure\"]\n",
    "    )\n",
    "    pearson_list.append(pearson[0])\n",
    "plt.plot(pearson_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig[\"y_lead_1\"] = df_orig[\"StationPressure\"].shift(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split lengths as per informer\n",
    "trn_length = int(24 * 365.25 * 2)\n",
    "val_test_length = int(24 * 365.25 * (10 / 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_list: List[nnts.experiments.CovariateScenario] = []\n",
    "\n",
    "# Add the baseline scenarios\n",
    "for seed in [42, 43, 44, 45, 46]:\n",
    "    scenario_list.append(\n",
    "        nnts.experiments.CovariateScenario(metadata.prediction_length, error=0.0, covariates=0, seed=seed)\n",
    "    )\n",
    "\n",
    "\n",
    "scenario_list = [\n",
    "    nnts.experiments.CovariateScenario(\n",
    "        metadata.prediction_length, error=0.0, covariates=1, seed=42\n",
    "    ),\n",
    "    nnts.experiments.CovariateScenario(1, error=0.0, covariates=1, seed=42),\n",
    "    nnts.experiments.CovariateScenario(1, error=0.0, covariates=0, seed=42),\n",
    "]\n",
    "scenario_list = [\n",
    "    nnts.experiments.CovariateScenario(\n",
    "        metadata.prediction_length, error=0.0, covariates=0, seed=42\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data, scenario):\n",
    "    pearson = 0\n",
    "    conts = []\n",
    "    noise = 0\n",
    "    if scenario.covariates > 0:\n",
    "        pearson = covs.calculate_pearson(data)\n",
    "        conts.append(\"y_lead_1\")\n",
    "    data = data.dropna()\n",
    "    scenario.conts = conts\n",
    "    scenario.pearson = pearson\n",
    "    scenario.noise = noise\n",
    "    return data, scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in scenario_list[:1]:\n",
    "    nnts.torch.data.datasets.seed_everything(scenario.seed)\n",
    "    df, scenario = prepare(df_orig.copy(), scenario)\n",
    "    split_data = splitter.split(\n",
    "        df, trn_length, val_test_length, val_test_length\n",
    "    )\n",
    "    trn_dl, val_dl, test_dl = nnts.data.map_to_dataloaders(\n",
    "        split_data,\n",
    "        metadata,\n",
    "        scenario,\n",
    "        params,\n",
    "        nnts.torch.data.TorchTimeseriesDataLoaderFactory(),\n",
    "        [nnts.torch.data.preprocessing.StandardScaler()],\n",
    "    )\n",
    "    logger = nnts.loggers.WandbRun(\n",
    "        project=f\"{model_name}-{metadata.dataset}\",\n",
    "        name=scenario.name,\n",
    "        config={\n",
    "            **params.__dict__,\n",
    "            **metadata.__dict__,\n",
    "            **scenario.__dict__,\n",
    "        },\n",
    "        path=PATH,\n",
    "    )\n",
    "\n",
    "    net = nnts.torch.models.SegLSTM(\n",
    "        nnts.torch.models.LinearModel,\n",
    "        params,\n",
    "        nnts.torch.data.preprocessing.masked_mean_abs_scaling,\n",
    "        scenario.covariates + 1,\n",
    "        24\n",
    "    )\n",
    "    trner = trainers.TorchEpochTrainer(\n",
    "        nnts.models.TrainerState(), \n",
    "        net, \n",
    "        params, \n",
    "        metadata, \n",
    "        os.path.join(PATH, f\"{scenario.name}.pt\"),\n",
    "    )\n",
    "    logger.configure(trner.events)\n",
    "\n",
    "    evaluator = trner.train(trn_dl, val_dl)\n",
    "    handle = net.decoder.register_forward_hook(logger.log_activations)\n",
    "    y_hat, y = evaluator.evaluate(\n",
    "        test_dl, scenario.prediction_length, metadata.context_length, hooks=handle\n",
    "    )\n",
    "    handle.remove()\n",
    "    test_metrics = nnts.metrics.calc_metrics(\n",
    "        y_hat, y, trn_dl, metadata\n",
    "    )\n",
    "    logger.log(test_metrics)\n",
    "    logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnts.metrics.calc_metrics(y_hat, y, trn_dl, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnts.metrics.calc_metrics(y_hat[:, :1, :], y[:, :1, :], trn_dl, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(y_hat, y, name):\n",
    "    torch.save(y_hat, f\"{PATH}/{name}_y_hat.pt\")\n",
    "    torch.save(y, f\"{PATH}/{name}_y.pt\")\n",
    "save_results(y_hat, y, scenario.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_name = f\"cov-1-pearsn-0.68-pl-{str(scenario.prediction_length)}-seed-{scenario.seed}\"\n",
    "covariate_y_hat = torch.load(f\"{PATH}/{covariate_name}_y_hat.pt\")\n",
    "covariate_y = torch.load(f\"{PATH}/{covariate_name}_y.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecast_horizon_metrics(y_hat, y, metadata, metric=\"mae\"):\n",
    "    forecast_horizon_metrics = []\n",
    "    for i in range(1, metadata.prediction_length):\n",
    "        metrics = nnts.metrics.calc_metrics(y[:, :i, :], y_hat[:, :i, :], metadata.freq, metadata.seasonality)\n",
    "        forecast_horizon_metrics.append(metrics[metric])\n",
    "    return forecast_horizon_metrics\n",
    "\n",
    "forecast_horizon_metrics = calculate_forecast_horizon_metrics(y_hat, y, metadata, \"mae\")\n",
    "covariate_forecast_horizon_metrics = calculate_forecast_horizon_metrics(covariate_y_hat, covariate_y, metadata, \"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(forecast_horizon_metrics, label='univariate')\n",
    "plt.plot(covariate_forecast_horizon_metrics, label='covariate (0.68)')\n",
    "plt.xlabel(\"Forecast Horizon\")\n",
    "plt.ylabel(\"Error (MAE)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_aggregator = nnts.pandas.CSVFileAggregator(PATH, \"results\")\n",
    "results = csv_aggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(metadata.prediction_length*50)['y'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_last = y_hat[:, :1, ...]\n",
    "y_last = y[:, :1, ...]\n",
    "df_test = df.tail(y_hat_last.shape[0])\n",
    "df_test[\"y_check\"] = y_last.squeeze()\n",
    "df_test[\"y_hat\"] = y_hat_last.squeeze()\n",
    "df_test[[\"y\", \"y_check\", \"y_hat\"]]\n",
    "df_test.set_index(\"ds\")[[\"y_check\", \"y_hat\"]].iloc[4500:4500+336].plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = nnts.metrics.calc_metrics(y_last, y_hat_last, metadata.freq, metadata.seasonality)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
