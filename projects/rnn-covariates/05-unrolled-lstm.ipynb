{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garethdavies/Development/workspaces/nnts/venv/lib/python3.11/site-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import List\n",
    "import seaborn as sns\n",
    "\n",
    "import nnts\n",
    "import nnts.data\n",
    "import nnts.experiments\n",
    "import nnts.models\n",
    "import nnts.torch.data.preprocessing as preprocessing\n",
    "import nnts.torch.models\n",
    "import nnts.torch.models.trainers as trainers\n",
    "import nnts.metrics\n",
    "import nnts.torch.data\n",
    "import nnts.torch.data.datasets\n",
    "import nnts.loggers\n",
    "import nnts.pandas\n",
    "import covs \n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnts.pandas\n",
    "\n",
    "df, *_ = nnts.pandas.read_tsf(\n",
    "    \"traffic_weekly_dataset.tsf\",\n",
    "    \"https://zenodo.org/records/4656135/files/traffic_weekly_dataset.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4875</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8092</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8881</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1613</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.3065</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.6545</td>\n",
       "      <td>2016-11-27</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.4925</td>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.4907</td>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.8985</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.1117</td>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y         ds unique_id\n",
       "0    6.4875 2015-01-04        T1\n",
       "1    7.8092 2015-01-11        T1\n",
       "2    6.8881 2015-01-18        T1\n",
       "3    7.1613 2015-01-25        T1\n",
       "4    8.3065 2015-02-01        T1\n",
       "..      ...        ...       ...\n",
       "99   5.6545 2016-11-27      T862\n",
       "100  6.4925 2016-12-04      T862\n",
       "101  6.4907 2016-12-11      T862\n",
       "102  6.8985 2016-12-18      T862\n",
       "103  6.1117 2016-12-25      T862\n",
       "\n",
       "[89648 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4875</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8092</td>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8881</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1613</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.3065</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.6545</td>\n",
       "      <td>2016-11-27</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.4925</td>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.4907</td>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6.8985</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.1117</td>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>T862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y         ds unique_id\n",
       "0    6.4875 2015-01-04        T1\n",
       "1    7.8092 2015-01-11        T1\n",
       "2    6.8881 2015-01-18        T1\n",
       "3    7.1613 2015-01-25        T1\n",
       "4    8.3065 2015-02-01        T1\n",
       "..      ...        ...       ...\n",
       "99   5.6545 2016-11-27      T862\n",
       "100  6.4925 2016-12-04      T862\n",
       "101  6.4907 2016-12-11      T862\n",
       "102  6.8985 2016-12-18      T862\n",
       "103  6.1117 2016-12-25      T862\n",
       "\n",
       "[89648 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nnts.loggers\n",
    "import nnts.pandas\n",
    "\n",
    "ARTICLE_PATH = \"nb-results/figures\"\n",
    "# ARTICLE_PATH = \"/Users/garethdavies/Development/workspaces/garethmd.github.io/articles/figures\"\n",
    "data_paths = {\n",
    "    \"traffic\": \"data/traffic_weekly_dataset.tsf\",\n",
    "    \"electricity\": \"data/electricity_hourly_dataset.tsf\",\n",
    "    \"tourism\": \"data/tourism_monthly_dataset.tsf\",\n",
    "    \"hospital\": \"data/hospital_dataset.tsf\",\n",
    "}\n",
    "results_path = \"nb-results\"\n",
    "metadata_path = \"monash.json\"\n",
    "nnts.pandas.read_tsf(path=data_paths[\"traffic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_PATH = \"nb-results/figures\"\n",
    "# ARTICLE_PATH = \"/Users/garethdavies/Development/workspaces/garethmd.github.io/articles/figures\"\n",
    "data_paths = {\n",
    "    \"traffic\": \"data/traffic_weekly_dataset.tsf\",\n",
    "    \"electricity\": \"data/electricity_hourly_dataset.tsf\",\n",
    "    \"tourism\": \"data/tourism_monthly_dataset.tsf\",\n",
    "    \"hospital\": \"data/hospital_dataset.tsf\",\n",
    "}\n",
    "results_path = \"nb-results\"\n",
    "metadata_path = \"monash.json\"\n",
    "nnts.loggers.makedirs_if_not_exists(ARTICLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"traffic\"\n",
    "df_orig, metadata = nnts.pandas.load(\n",
    "    dataset_name, metadata_path=metadata_path\n",
    ")\n",
    "\n",
    "params = nnts.models.Hyperparams()\n",
    "params.training_method = nnts.models.hyperparams.TrainingMethod.FREE_RUNNING\n",
    "splitter = nnts.data.PandasSplitter()\n",
    "model_name = \"unrolled-lstm\"\n",
    "PATH = f\"results/{model_name}/{metadata.dataset}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_list: List[nnts.experiments.CovariateScenario] = []\n",
    "\n",
    "# Add the baseline scenarios\n",
    "for seed in [42, 43, 44, 45, 46]:\n",
    "    scenario_list.append(\n",
    "        nnts.experiments.CovariateScenario(metadata.prediction_length, error=0.0, covariates=0, seed=seed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Models for full forecast horizon with covariates\n",
    "\n",
    "for covariates in [1, 2, 3]:\n",
    "    for error in covs.errors[metadata.dataset]:\n",
    "        scenario_list.append( \n",
    "            nnts.experiments.CovariateScenario(\n",
    "                metadata.prediction_length, error, covariates=covariates\n",
    "            )\n",
    "        )\n",
    "\n",
    "scenario_list.append( \n",
    "    nnts.experiments.CovariateScenario(\n",
    "        metadata.prediction_length, 0, covariates=3, skip=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnrolledLSTM(\n",
      "  (decoder): UnrolledLSTMDecoder(\n",
      "    (rnn): LSTM(2, 40, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  )\n",
      "  (distribution): LinearModel(\n",
      "    (main): Sequential(\n",
      "      (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=40, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 1629.0181884765625, 'valid_loss': 5415.83935546875, 'elapsed_time': 12.651964166667312}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 856.6263427734375, 'valid_loss': 5385.62548828125, 'elapsed_time': 11.181081290822476}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 809.2552490234375, 'valid_loss': 5358.765625, 'elapsed_time': 11.286123166792095}\n",
      "{'train_loss': 807.2147827148438, 'valid_loss': 5400.69287109375, 'elapsed_time': 11.20332658290863}\n",
      "{'train_loss': 786.5203247070312, 'valid_loss': 5441.43359375, 'elapsed_time': 11.210077333264053}\n",
      "{'train_loss': 794.78857421875, 'valid_loss': 5416.27880859375, 'elapsed_time': 11.994266834110022}\n",
      "{'train_loss': 797.3495483398438, 'valid_loss': 5382.26416015625, 'elapsed_time': 11.85903162509203}\n",
      "{'train_loss': 806.1847534179688, 'valid_loss': 5391.38232421875, 'elapsed_time': 11.13749812496826}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 784.4998168945312, 'valid_loss': 5339.939453125, 'elapsed_time': 11.476334958337247}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 774.8621826171875, 'valid_loss': 5338.78076171875, 'elapsed_time': 11.16380075039342}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 813.22119140625, 'valid_loss': 5312.78271484375, 'elapsed_time': 12.082337957806885}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 724.0011596679688, 'valid_loss': 4807.078125, 'elapsed_time': 11.305939207784832}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 632.823974609375, 'valid_loss': 4424.74169921875, 'elapsed_time': 11.239261250011623}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 566.9426879882812, 'valid_loss': 4223.09423828125, 'elapsed_time': 11.255157249979675}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 535.6640625, 'valid_loss': 4165.2763671875, 'elapsed_time': 11.596382249612361}\n",
      "{'train_loss': 570.6296997070312, 'valid_loss': 4186.76220703125, 'elapsed_time': 12.19595908280462}\n",
      "{'train_loss': 539.2647094726562, 'valid_loss': 4319.06396484375, 'elapsed_time': 11.443954541813582}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 545.5963745117188, 'valid_loss': 4070.262451171875, 'elapsed_time': 11.394649291876704}\n",
      "{'train_loss': 540.7265625, 'valid_loss': 4083.225830078125, 'elapsed_time': 11.259453250095248}\n",
      "{'train_loss': 535.1033325195312, 'valid_loss': 4329.0517578125, 'elapsed_time': 14.658499249722809}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 531.3003540039062, 'valid_loss': 3994.058837890625, 'elapsed_time': 12.047242916189134}\n",
      "{'train_loss': 528.6193237304688, 'valid_loss': 4001.951416015625, 'elapsed_time': 11.673787625040859}\n",
      "{'train_loss': 536.3797607421875, 'valid_loss': 4149.53759765625, 'elapsed_time': 11.125806791707873}\n",
      "{'train_loss': 531.2728271484375, 'valid_loss': 4173.9794921875, 'elapsed_time': 11.208231959026307}\n",
      "{'train_loss': 521.2042236328125, 'valid_loss': 4176.09326171875, 'elapsed_time': 11.188213500194252}\n",
      "{'train_loss': 523.7369384765625, 'valid_loss': 4059.46484375, 'elapsed_time': 11.614152042195201}\n",
      "{'train_loss': 535.7054443359375, 'valid_loss': 4025.564453125, 'elapsed_time': 12.626422083005309}\n",
      "{'train_loss': 538.162353515625, 'valid_loss': 4052.429931640625, 'elapsed_time': 12.167671999894083}\n",
      "{'train_loss': 513.6702270507812, 'valid_loss': 4213.26123046875, 'elapsed_time': 11.117314958013594}\n",
      "{'train_loss': 517.0244750976562, 'valid_loss': 4239.06640625, 'elapsed_time': 13.48751554172486}\n",
      "{'train_loss': 518.4368896484375, 'valid_loss': 4252.53369140625, 'elapsed_time': 12.010752458125353}\n",
      "{'train_loss': 503.9798583984375, 'valid_loss': 4419.47998046875, 'elapsed_time': 12.047638082876801}\n",
      "{'train_loss': 509.0984802246094, 'valid_loss': 4374.06640625, 'elapsed_time': 11.454662499949336}\n",
      "{'train_loss': 510.4095764160156, 'valid_loss': 4244.12060546875, 'elapsed_time': 10.93225266598165}\n",
      "{'train_loss': 502.770263671875, 'valid_loss': 4018.376220703125, 'elapsed_time': 11.276686375029385}\n",
      "{'train_loss': 510.0948791503906, 'valid_loss': 4151.140625, 'elapsed_time': 11.264715709257871}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 497.0561828613281, 'valid_loss': 3927.447265625, 'elapsed_time': 12.772626790683717}\n",
      "{'train_loss': 514.8236083984375, 'valid_loss': 4399.04638671875, 'elapsed_time': 12.033127082977444}\n",
      "{'train_loss': 509.7790832519531, 'valid_loss': 4250.39404296875, 'elapsed_time': 11.338285374920815}\n",
      "{'train_loss': 492.9115295410156, 'valid_loss': 4188.11669921875, 'elapsed_time': 11.373842500150204}\n",
      "{'train_loss': 504.9868469238281, 'valid_loss': 4378.84912109375, 'elapsed_time': 11.057369499932975}\n",
      "{'train_loss': 506.4095458984375, 'valid_loss': 4051.059814453125, 'elapsed_time': 13.041519083082676}\n",
      "{'train_loss': 516.7471313476562, 'valid_loss': 4546.72021484375, 'elapsed_time': 11.759206833317876}\n",
      "{'train_loss': 487.96966552734375, 'valid_loss': 3988.500244140625, 'elapsed_time': 11.431354666128755}\n",
      "{'train_loss': 496.3667907714844, 'valid_loss': 4325.7138671875, 'elapsed_time': 11.14435562491417}\n",
      "{'train_loss': 492.4307556152344, 'valid_loss': 4377.14892578125, 'elapsed_time': 10.640316999983042}\n",
      "{'train_loss': 483.7706604003906, 'valid_loss': 4267.75341796875, 'elapsed_time': 10.559381333179772}\n",
      "{'train_loss': 514.4806518554688, 'valid_loss': 4492.17919921875, 'elapsed_time': 11.161843874957412}\n",
      "{'train_loss': 505.1000061035156, 'valid_loss': 4051.825439453125, 'elapsed_time': 11.171684249769896}\n",
      "{'train_loss': 506.88482666015625, 'valid_loss': 4075.660888671875, 'elapsed_time': 11.756560292094946}\n",
      "{'train_loss': 482.3612365722656, 'valid_loss': 4029.525634765625, 'elapsed_time': 11.283554416615516}\n",
      "{'train_loss': 499.8156433105469, 'valid_loss': 4252.16357421875, 'elapsed_time': 11.172521290834993}\n",
      "{'train_loss': 490.9054870605469, 'valid_loss': 4608.57666015625, 'elapsed_time': 12.227092375047505}\n",
      "{'train_loss': 498.8189697265625, 'valid_loss': 4170.17578125, 'elapsed_time': 11.662263416219503}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-42.pt\n",
      "{'train_loss': 490.83599853515625, 'valid_loss': 3695.30859375, 'elapsed_time': 11.287825957871974}\n",
      "{'train_loss': 500.3136901855469, 'valid_loss': 4380.76220703125, 'elapsed_time': 11.569063125178218}\n",
      "{'train_loss': 484.95306396484375, 'valid_loss': 4400.01123046875, 'elapsed_time': 11.613213791046292}\n",
      "{'train_loss': 494.4913635253906, 'valid_loss': 4484.76220703125, 'elapsed_time': 12.873500207904726}\n",
      "{'train_loss': 482.13409423828125, 'valid_loss': 4356.146484375, 'elapsed_time': 11.788790415972471}\n",
      "{'train_loss': 490.752197265625, 'valid_loss': 4120.96630859375, 'elapsed_time': 12.152366291731596}\n",
      "{'train_loss': 491.06146240234375, 'valid_loss': 4084.575927734375, 'elapsed_time': 12.394711916800588}\n",
      "{'train_loss': 478.83135986328125, 'valid_loss': 4307.77294921875, 'elapsed_time': 13.136478500440717}\n",
      "{'train_loss': 467.8592224121094, 'valid_loss': 4324.35595703125, 'elapsed_time': 12.846151750069112}\n",
      "{'train_loss': 454.2299499511719, 'valid_loss': 4274.7841796875, 'elapsed_time': 12.788224750198424}\n",
      "{'train_loss': 474.9921875, 'valid_loss': 4057.870849609375, 'elapsed_time': 13.342314416076988}\n",
      "{'train_loss': 451.8107604980469, 'valid_loss': 4299.298828125, 'elapsed_time': 11.507882416713983}\n",
      "{'train_loss': 449.0184020996094, 'valid_loss': 4448.52490234375, 'elapsed_time': 11.929119875188917}\n",
      "{'train_loss': 456.287841796875, 'valid_loss': 4318.1328125, 'elapsed_time': 12.46218154206872}\n",
      "{'train_loss': 443.5531921386719, 'valid_loss': 4224.2509765625, 'elapsed_time': 11.544124375097454}\n",
      "{'train_loss': 431.1151123046875, 'valid_loss': 4432.67041015625, 'elapsed_time': 11.47852687491104}\n",
      "{'train_loss': 447.4087829589844, 'valid_loss': 4572.88134765625, 'elapsed_time': 12.41670179180801}\n",
      "{'train_loss': 436.6511535644531, 'valid_loss': 4364.14501953125, 'elapsed_time': 11.458812791854143}\n",
      "{'train_loss': 433.76458740234375, 'valid_loss': 4437.52099609375, 'elapsed_time': 12.997763375286013}\n",
      "{'train_loss': 430.4979248046875, 'valid_loss': 4577.11181640625, 'elapsed_time': 12.91939145885408}\n",
      "{'train_loss': 428.3782653808594, 'valid_loss': 4450.17041015625, 'elapsed_time': 11.311448082793504}\n",
      "{'train_loss': 438.15325927734375, 'valid_loss': 4444.376953125, 'elapsed_time': 13.28234283393249}\n",
      "{'train_loss': 428.65277099609375, 'valid_loss': 4334.82080078125, 'elapsed_time': 11.582653291989118}\n",
      "{'train_loss': 428.194580078125, 'valid_loss': 4557.8564453125, 'elapsed_time': 11.334930957760662}\n",
      "{'train_loss': 424.9934387207031, 'valid_loss': 4299.794921875, 'elapsed_time': 11.441926749888808}\n",
      "{'train_loss': 405.9697265625, 'valid_loss': 4421.3935546875, 'elapsed_time': 12.58846691576764}\n",
      "{'train_loss': 419.8286437988281, 'valid_loss': 4573.39453125, 'elapsed_time': 16.84091941593215}\n",
      "{'train_loss': 408.92572021484375, 'valid_loss': 4583.68212890625, 'elapsed_time': 15.39935691608116}\n",
      "{'train_loss': 405.711181640625, 'valid_loss': 4552.27978515625, 'elapsed_time': 12.51487520802766}\n",
      "{'train_loss': 423.7215576171875, 'valid_loss': 4559.61083984375, 'elapsed_time': 11.898775416892022}\n",
      "early stopping\n",
      "{'train_loss': 407.56439208984375, 'valid_loss': 4339.16650390625, 'elapsed_time': 11.984535166993737}\n",
      "{'mse': 137670030.0, 'mae': 3150.12744140625, 'mape': 0.34846815, 'smape': 0.26165059208869934, 'abs_error': 27670720.0, 'mase': 0.11169513, 'rmse': 3954.362060546875}\n",
      "Run cov-0-pearsn-0-pl-24-seed-42 finished\n",
      "UnrolledLSTM(\n",
      "  (decoder): UnrolledLSTMDecoder(\n",
      "    (rnn): LSTM(2, 40, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  )\n",
      "  (distribution): LinearModel(\n",
      "    (main): Sequential(\n",
      "      (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=40, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 1743.0850830078125, 'valid_loss': 5363.06396484375, 'elapsed_time': 11.815826541744173}\n",
      "{'train_loss': 857.9087524414062, 'valid_loss': 5364.92822265625, 'elapsed_time': 11.794622083194554}\n",
      "{'train_loss': 821.9500122070312, 'valid_loss': 5389.26123046875, 'elapsed_time': 11.699492875020951}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 816.4449462890625, 'valid_loss': 5338.845703125, 'elapsed_time': 13.253726791124791}\n",
      "{'train_loss': 799.0509033203125, 'valid_loss': 5344.306640625, 'elapsed_time': 12.841330166906118}\n",
      "{'train_loss': 793.6229858398438, 'valid_loss': 5395.59228515625, 'elapsed_time': 13.414346291683614}\n",
      "{'train_loss': 783.252197265625, 'valid_loss': 5432.37109375, 'elapsed_time': 12.309600000269711}\n",
      "{'train_loss': 762.2045288085938, 'valid_loss': 5376.24267578125, 'elapsed_time': 11.693834957666695}\n",
      "{'train_loss': 766.1268310546875, 'valid_loss': 5419.021484375, 'elapsed_time': 14.426957332994789}\n",
      "{'train_loss': 771.9778442382812, 'valid_loss': 5409.81591796875, 'elapsed_time': 12.483137041795999}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 776.253662109375, 'valid_loss': 5301.23779296875, 'elapsed_time': 11.055486750323325}\n",
      "{'train_loss': 773.5363159179688, 'valid_loss': 5318.17724609375, 'elapsed_time': 12.22204195894301}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 769.9530639648438, 'valid_loss': 5274.44384765625, 'elapsed_time': 11.654365666676313}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 688.7717895507812, 'valid_loss': 4682.82568359375, 'elapsed_time': 11.195870082825422}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 587.6571655273438, 'valid_loss': 4359.04052734375, 'elapsed_time': 12.414531291928142}\n",
      "{'train_loss': 581.64501953125, 'valid_loss': 4361.60498046875, 'elapsed_time': 12.915228874888271}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 561.9818115234375, 'valid_loss': 4291.80615234375, 'elapsed_time': 14.68782391725108}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 551.9619140625, 'valid_loss': 4237.29150390625, 'elapsed_time': 13.073452332988381}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 547.190673828125, 'valid_loss': 3931.978759765625, 'elapsed_time': 14.443525333888829}\n",
      "{'train_loss': 536.0390625, 'valid_loss': 4290.45947265625, 'elapsed_time': 11.642269749660045}\n",
      "{'train_loss': 542.19189453125, 'valid_loss': 4329.583984375, 'elapsed_time': 11.089344874955714}\n",
      "{'train_loss': 542.037841796875, 'valid_loss': 4315.03466796875, 'elapsed_time': 14.092433041892946}\n",
      "{'train_loss': 521.225830078125, 'valid_loss': 4338.24462890625, 'elapsed_time': 13.361312790773809}\n",
      "{'train_loss': 538.18701171875, 'valid_loss': 4287.1416015625, 'elapsed_time': 13.338951707817614}\n",
      "{'train_loss': 528.7766723632812, 'valid_loss': 4099.29345703125, 'elapsed_time': 13.189294290728867}\n",
      "{'train_loss': 516.316650390625, 'valid_loss': 4324.62451171875, 'elapsed_time': 11.905854958109558}\n",
      "{'train_loss': 518.733154296875, 'valid_loss': 4152.03369140625, 'elapsed_time': 12.128961292095482}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 515.94775390625, 'valid_loss': 3853.343505859375, 'elapsed_time': 11.433877915609628}\n",
      "{'train_loss': 518.7642211914062, 'valid_loss': 4249.27734375, 'elapsed_time': 13.010027666110545}\n",
      "{'train_loss': 526.4613037109375, 'valid_loss': 4328.14306640625, 'elapsed_time': 15.988624916877598}\n",
      "{'train_loss': 520.461181640625, 'valid_loss': 4109.97021484375, 'elapsed_time': 12.595410542096943}\n",
      "{'train_loss': 513.1681518554688, 'valid_loss': 4176.0458984375, 'elapsed_time': 11.673769332934171}\n",
      "{'train_loss': 500.1914978027344, 'valid_loss': 4146.54638671875, 'elapsed_time': 13.161036750301719}\n",
      "{'train_loss': 517.8515014648438, 'valid_loss': 4164.1904296875, 'elapsed_time': 13.902856042142957}\n",
      "{'train_loss': 516.07763671875, 'valid_loss': 4175.89453125, 'elapsed_time': 14.22695520799607}\n",
      "{'train_loss': 512.2813110351562, 'valid_loss': 4139.9296875, 'elapsed_time': 12.568109541200101}\n",
      "{'train_loss': 512.27978515625, 'valid_loss': 4506.73583984375, 'elapsed_time': 11.25027974974364}\n",
      "{'train_loss': 499.30657958984375, 'valid_loss': 4148.23486328125, 'elapsed_time': 11.035240000113845}\n",
      "{'train_loss': 509.86236572265625, 'valid_loss': 4233.58349609375, 'elapsed_time': 11.185768791940063}\n",
      "{'train_loss': 521.3533325195312, 'valid_loss': 4264.34326171875, 'elapsed_time': 11.542729166802019}\n",
      "{'train_loss': 516.1754150390625, 'valid_loss': 4341.57421875, 'elapsed_time': 12.131653832737356}\n",
      "{'train_loss': 499.6778869628906, 'valid_loss': 4754.09521484375, 'elapsed_time': 11.15271058306098}\n",
      "{'train_loss': 508.6549072265625, 'valid_loss': 4346.58740234375, 'elapsed_time': 11.232847124803811}\n",
      "{'train_loss': 500.81805419921875, 'valid_loss': 4758.67138671875, 'elapsed_time': 11.187649124767631}\n",
      "{'train_loss': 511.1694030761719, 'valid_loss': 4182.97509765625, 'elapsed_time': 11.344032667111605}\n",
      "{'train_loss': 500.6338806152344, 'valid_loss': 4520.45263671875, 'elapsed_time': 11.856212791986763}\n",
      "{'train_loss': 501.399658203125, 'valid_loss': 3992.453125, 'elapsed_time': 11.273092249874026}\n",
      "{'train_loss': 501.9537353515625, 'valid_loss': 4037.617919921875, 'elapsed_time': 11.155119707807899}\n",
      "{'train_loss': 500.6498718261719, 'valid_loss': 4774.16162109375, 'elapsed_time': 11.563150249887258}\n",
      "{'train_loss': 512.1280517578125, 'valid_loss': 4300.25, 'elapsed_time': 11.75261954171583}\n",
      "Artifact saved to results/unrolled-lstm/tourism/cov-0-pearsn-0-pl-24-seed-43.pt\n",
      "{'train_loss': 499.95733642578125, 'valid_loss': 3805.115478515625, 'elapsed_time': 11.521905709058046}\n",
      "{'train_loss': 489.435546875, 'valid_loss': 4488.837890625, 'elapsed_time': 12.386588832829148}\n",
      "{'train_loss': 503.5235900878906, 'valid_loss': 4614.1220703125, 'elapsed_time': 14.326804665848613}\n",
      "{'train_loss': 497.66595458984375, 'valid_loss': 4275.513671875, 'elapsed_time': 12.323952374979854}\n",
      "{'train_loss': 489.3376770019531, 'valid_loss': 4304.20849609375, 'elapsed_time': 12.942104957997799}\n",
      "{'train_loss': 472.2192077636719, 'valid_loss': 4191.35302734375, 'elapsed_time': 13.305953750386834}\n",
      "{'train_loss': 485.4765625, 'valid_loss': 4301.75390625, 'elapsed_time': 12.915606750175357}\n",
      "{'train_loss': 503.548095703125, 'valid_loss': 4385.64013671875, 'elapsed_time': 11.641553499735892}\n",
      "{'train_loss': 494.5942687988281, 'valid_loss': 4731.49365234375, 'elapsed_time': 11.56060995766893}\n",
      "{'train_loss': 498.0120849609375, 'valid_loss': 4399.32958984375, 'elapsed_time': 11.69699779106304}\n",
      "{'train_loss': 494.7845764160156, 'valid_loss': 4388.3818359375, 'elapsed_time': 12.064822542015463}\n",
      "{'train_loss': 467.3947448730469, 'valid_loss': 4408.98095703125, 'elapsed_time': 12.844102625269443}\n",
      "{'train_loss': 471.0004577636719, 'valid_loss': 4320.04150390625, 'elapsed_time': 11.918732750229537}\n",
      "{'train_loss': 475.7502136230469, 'valid_loss': 4219.93017578125, 'elapsed_time': 12.039800458122045}\n",
      "{'train_loss': 467.6058349609375, 'valid_loss': 4382.81689453125, 'elapsed_time': 13.806026208214462}\n",
      "{'train_loss': 480.2724609375, 'valid_loss': 4199.66552734375, 'elapsed_time': 15.110848207958043}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 40\u001b[0m\n\u001b[1;32m     26\u001b[0m net \u001b[38;5;241m=\u001b[39m nnts\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mUnrolledLSTM(\n\u001b[1;32m     27\u001b[0m     nnts\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mLinearModel,\n\u001b[1;32m     28\u001b[0m     params,\n\u001b[1;32m     29\u001b[0m     preprocessing\u001b[38;5;241m.\u001b[39mmasked_mean_abs_scaling,\n\u001b[1;32m     30\u001b[0m     scenario\u001b[38;5;241m.\u001b[39mcovariates \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m trner \u001b[38;5;241m=\u001b[39m trainers\u001b[38;5;241m.\u001b[39mTorchEpochTrainer(\n\u001b[1;32m     33\u001b[0m     nnts\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mTrainerState(), \n\u001b[1;32m     34\u001b[0m     net, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mtrner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m y_hat, y  \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m     42\u001b[0m     test_dl, scenario\u001b[38;5;241m.\u001b[39mprediction_length, metadata\u001b[38;5;241m.\u001b[39mcontext_length\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m nnts\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mcalc_metrics(\n\u001b[1;32m     45\u001b[0m     y, y_hat, metadata\u001b[38;5;241m.\u001b[39mfreq, metadata\u001b[38;5;241m.\u001b[39mseasonality\n\u001b[1;32m     46\u001b[0m )\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/nnts/models/trainers.py:51\u001b[0m, in \u001b[0;36mEpochTrainer.train\u001b[0;34m(self, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_epoch(valid_dl)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_evaluator()\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/nnts/models/trainers.py:65\u001b[0m, in \u001b[0;36mEpochTrainer._train_epoch\u001b[0;34m(self, train_dl)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mbatches_per_epoch:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m L\n\u001b[1;32m     67\u001b[0m loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl)\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/nnts/torch/models/trainers.py:153\u001b[0m, in \u001b[0;36mTorchEpochTrainer._train_batch\u001b[0;34m(self, i, batch)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtraining_method\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;241m==\u001b[39m nnts\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mhyperparams\u001b[38;5;241m.\u001b[39mTrainingMethod\u001b[38;5;241m.\u001b[39mFREE_RUNNING\n\u001b[1;32m    152\u001b[0m ):\n\u001b[0;32m--> 153\u001b[0m     y_hat, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfree_running\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     y_hat, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mteacher_forcing_output(batch)\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/nnts/torch/models/unrolledlstm.py:111\u001b[0m, in \u001b[0;36mUnrolledLSTM.free_running\u001b[0;34m(self, data, context_length, prediction_length)\u001b[0m\n\u001b[1;32m    107\u001b[0m pad_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    109\u001b[0m y \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m1\u001b[39m:, :]\n\u001b[0;32m--> 111\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m y_hat[pad_mask[:, \u001b[38;5;241m1\u001b[39m:]]\n\u001b[1;32m    117\u001b[0m y \u001b[38;5;241m=\u001b[39m y[pad_mask[:, \u001b[38;5;241m1\u001b[39m:]]\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/nnts/torch/models/unrolledlstm.py:83\u001b[0m, in \u001b[0;36mUnrolledLSTM.forward\u001b[0;34m(self, X, pad_mask, H)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, H):\n\u001b[1;32m     82\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:, :], torch\u001b[38;5;241m.\u001b[39mlog(target_scale[:, :, :\u001b[38;5;241m1\u001b[39m])], \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution(out, target_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m     y_hat[:, T \u001b[38;5;241m+\u001b[39m t, :] \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/nnts/torch/models/unrolledlstm.py:50\u001b[0m, in \u001b[0;36mUnrolledLSTMDecoder.forward\u001b[0;34m(self, X, hidden)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden_zeros(B)\n\u001b[0;32m---> 50\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, hidden\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/workspaces/nnts/venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for scenario in scenario_list:\n",
    "    nnts.torch.data.datasets.seed_everything(scenario.seed)\n",
    "    df, scenario = covs.prepare(df_orig.copy(), scenario)\n",
    "    split_data = splitter.split(df, metadata)\n",
    "    trn_dl, val_dl, test_dl = nnts.data.map_to_dataloaders(\n",
    "        split_data,\n",
    "        metadata,\n",
    "        scenario,\n",
    "        params,\n",
    "        nnts.torch.data.TorchTimeseriesDataLoaderFactory(),\n",
    "    )\n",
    "    logger = nnts.loggers.ProjectRun(\n",
    "        nnts.loggers.JsonFileHandler(\n",
    "            path=PATH, filename=f\"{scenario.name}.json\"\n",
    "        ),\n",
    "        #nnts.loggers.PrintHandler(),\n",
    "        project=f\"{model_name}-{metadata.dataset}\",\n",
    "        run=scenario.name,\n",
    "        config={\n",
    "            **params.__dict__,\n",
    "            **metadata.__dict__,\n",
    "            **scenario.__dict__,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    net = nnts.torch.models.UnrolledLSTM(\n",
    "        nnts.torch.models.LinearModel,\n",
    "        params,\n",
    "        preprocessing.masked_mean_abs_scaling,\n",
    "        scenario.covariates + 1,\n",
    "    )\n",
    "    trner = trainers.TorchEpochTrainer(\n",
    "        nnts.models.TrainerState(), \n",
    "        net, \n",
    "        params, \n",
    "        metadata, \n",
    "        f\"{PATH}/{scenario.name}.pt\",\n",
    "        logger=logger\n",
    "    )\n",
    "    evaluator = trner.train(trn_dl, val_dl)\n",
    "    y_hat, y  = evaluator.evaluate(\n",
    "        test_dl, scenario.prediction_length, metadata.context_length\n",
    "    )\n",
    "    test_metrics = nnts.metrics.calc_metrics(\n",
    "        y, y_hat, metadata.freq, metadata.seasonality\n",
    "    )\n",
    "    logger.log(test_metrics)\n",
    "    logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'covs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m csv_aggregator \u001b[38;5;241m=\u001b[39m \u001b[43mcovs\u001b[49m\u001b[38;5;241m.\u001b[39mCSVFileAggregator(PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m csv_aggregator()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'covs' is not defined"
     ]
    }
   ],
   "source": [
    "csv_aggregator = covs.CSVFileAggregator(PATH, \"results\")\n",
    "results = csv_aggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#results = pd.read_csv(f\"{PATH}/results.csv\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m5\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     covs\u001b[38;5;241m.\u001b[39mget_chart_data(results, metadata\u001b[38;5;241m.\u001b[39mprediction_length, \u001b[38;5;241m1\u001b[39m, metric)\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m      6\u001b[0m         kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         ax\u001b[38;5;241m=\u001b[39maxes[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      8\u001b[0m         title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m covariates = 1, forecast horizon = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata\u001b[38;5;241m.\u001b[39mprediction_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     covs\u001b[38;5;241m.\u001b[39mget_chart_data(results, metadata\u001b[38;5;241m.\u001b[39mprediction_length, \u001b[38;5;241m2\u001b[39m, metric)\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m     11\u001b[0m         kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m         ax\u001b[38;5;241m=\u001b[39maxes[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     13\u001b[0m         title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m covariates = 2, forecast horizon = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata\u001b[38;5;241m.\u001b[39mprediction_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#results = pd.read_csv(f\"{PATH}/results.csv\")\n",
    "\n",
    "for metric in [\"smape\", \"mape\", \"rmse\", \"mae\"]:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5), sharey=True)\n",
    "    covs.get_chart_data(results, metadata.prediction_length, 1, metric).plot(\n",
    "        kind=\"line\",\n",
    "        ax=axes[0],\n",
    "        title=f\"{metadata.dataset} {metric} covariates = 1, forecast horizon = {metadata.prediction_length}\",\n",
    "    )\n",
    "    covs.get_chart_data(results, metadata.prediction_length, 2, metric).plot(\n",
    "        kind=\"line\",\n",
    "        ax=axes[1],\n",
    "        title=f\"{metadata.dataset} {metric} covariates = 2, forecast horizon = {metadata.prediction_length}\",\n",
    "    )\n",
    "    covs.get_chart_data(results, metadata.prediction_length, 3, metric).plot(\n",
    "        kind=\"line\",\n",
    "        ax=axes[2],\n",
    "        title=f\"{metadata.dataset} {metric} covariates = 3, forecast horizon = {metadata.prediction_length}\",\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{PATH}/{metric}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = covs.add_y_hat(df, y_hat, scenario.prediction_length)\n",
    "sample_preds = covs.plot(df_list, scenario.prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_results = results.loc[\n",
    "    (results[\"covariates\"] == 0)\n",
    "    & (results[\"prediction_length\"] == metadata.prediction_length),\n",
    "    [\"smape\", \"mape\", \"rmse\", \"mae\"],\n",
    "]\n",
    "\n",
    "univariate_results.mean(), univariate_results.std(), univariate_results.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"dataset\", \"error\", \"pearson\", \"covariates\", \"prediction_length\", \"smape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[\n",
    "    (results[\"covariates\"] > 0)\n",
    "    & (results[\"error\"].isin([0.000000, 0.4714285714285714, 1.65])),\n",
    "    cols,\n",
    "].sort_values(by=[\"covariates\", \"error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(results[\"error\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1149.8700</td>\n",
       "      <td>1979-01-31</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1053.8002</td>\n",
       "      <td>1979-02-28</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1388.8798</td>\n",
       "      <td>1979-03-31</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1783.3702</td>\n",
       "      <td>1979-04-30</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1921.0252</td>\n",
       "      <td>1979-05-31</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>7778.0000</td>\n",
       "      <td>2000-08-31</td>\n",
       "      <td>T366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>7859.0000</td>\n",
       "      <td>2000-09-30</td>\n",
       "      <td>T366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>4802.0000</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>T366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2426.0000</td>\n",
       "      <td>2000-11-30</td>\n",
       "      <td>T366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>637.0000</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>T366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y         ds unique_id\n",
       "0    1149.8700 1979-01-31        T1\n",
       "1    1053.8002 1979-02-28        T1\n",
       "2    1388.8798 1979-03-31        T1\n",
       "3    1783.3702 1979-04-30        T1\n",
       "4    1921.0252 1979-05-31        T1\n",
       "..         ...        ...       ...\n",
       "235  7778.0000 2000-08-31      T366\n",
       "236  7859.0000 2000-09-30      T366\n",
       "237  4802.0000 2000-10-31      T366\n",
       "238  2426.0000 2000-11-30      T366\n",
       "239   637.0000 2000-12-31      T366\n",
       "\n",
       "[109280 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
