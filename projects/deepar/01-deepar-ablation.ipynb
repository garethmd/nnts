{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "from typing import List\n",
                "import pandas as pd\n",
                "import gluonts\n",
                "import nnts\n",
                "import nnts.data\n",
                "import nnts.experiments\n",
                "from nnts import utils, datasets\n",
                "import nnts.torch.preprocessing\n",
                "import nnts.torch.models\n",
                "import trainers\n",
                "import nnts.metrics\n",
                "import nnts.torch.datasets\n",
                "import nnts.loggers\n",
                "import nnts\n",
                "import nnts.experiments.plotting\n",
                "import deepar\n",
                "#from deepar import LagScenario\n",
                "\n",
                "import torch.nn.functional as F\n",
                "\n",
                "torch.set_printoptions(precision=8, sci_mode=False)\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = \"data\"\n",
                "model_name = \"deepar\"\n",
                "base_model_name = \"base-lstm\"\n",
                "dataset_name = \"tourism_monthly\"\n",
                "results_path = \"ablation-results\"\n",
                "metadata_path = os.path.join(data_path, f\"{base_model_name}-monash.json\")\n",
                "metadata = datasets.load_metadata(dataset_name, path=metadata_path)\n",
                "datafile_path = os.path.join(data_path, metadata.filename)\n",
                "PATH = os.path.join(results_path, model_name, metadata.dataset)\n",
                "\n",
                "df_orig, *_ = datasets.read_tsf(datafile_path)\n",
                "params = utils.Hyperparams(optimizer = torch.optim.Adam, loss_fn=F.smooth_l1_loss)\n",
                "\n",
                "utils.makedirs_if_not_exists(PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Gluonts defaults\n",
                "params.batch_size = 32\n",
                "params.batches_per_epoch = 50"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_org = deepar.create_time_features(df_orig)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GlounTS uses the following code to generate the month covariate used in the tourism dataset\n",
                "# the month value is extracted from the date column and then scaled to a value between -0.5 and 0.5\n",
                "# here we do this is on the whole dataset in one go\n",
                "max_min_scaler = nnts.torch.data.preprocessing.MaxMinScaler()\n",
                "max_min_scaler.fit(df_orig, [\"month\", \"week\", \"day_of_week\", \"hour\"])\n",
                "df_orig = max_min_scaler.transform(df_orig, [\"month\", \"week\", \"day_of_week\", \"hour\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ax = df_orig[df_orig['unique_id'] == 'T1'].set_index('ds').tail(36)['month'].plot(figsize=(20, 5))\n",
                "fig = ax.get_figure()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass, field\n",
                "lag_seq = gluonts.time_feature.lag.get_lags_for_frequency(metadata.freq)\n",
                "lag_seq = [lag - 1 for lag in lag_seq if lag > 1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaled_covariates = [\"month\", \"unix_timestamp\", nnts.torch.models.deepar.FEAT_SCALE]\n",
                "scaled_covariate_selection_matrix = [\n",
                "    [0,0,1],\n",
                "    [0,1,0],\n",
                "    [0,1,1],\n",
                "    [1,0,0],\n",
                "    [1,0,1],\n",
                "    [1,1,0],\n",
                "    [1,1,1],\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scenario_list: List[nnts.experiments.Scenario] = []\n",
                "\n",
                "for seed in [42, 43, 44, 45, 46]:\n",
                "    for row in scaled_covariate_selection_matrix:\n",
                "        selected_combination = [\n",
                "            covariate\n",
                "            for covariate, select in zip(scaled_covariates, row)\n",
                "            if select == 1\n",
                "        ]\n",
                "        scenario_list.append(\n",
                "            LagScenario(\n",
                "                metadata.prediction_length,\n",
                "                conts=[cov for cov in selected_combination if cov != nnts.torch.models.deepar.FEAT_SCALE],\n",
                "                scaled_covariates=selected_combination,\n",
                "                lag_seq=lag_seq,\n",
                "                seed=seed,\n",
                "                dataset=metadata.dataset,\n",
                "            )\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add the baseline scenarios\n",
                "scenario_list: List[nnts.experiments.Scenario] = []\n",
                "for seed in [42, 43, 44, 45, 46]:\n",
                "    scenario = LagScenario(\n",
                "        metadata.prediction_length,\n",
                "        conts=[],\n",
                "        scaled_covariates=[],\n",
                "        lag_seq=lag_seq,\n",
                "        seed=seed,\n",
                "        dataset=metadata.dataset,\n",
                "    )\n",
                "    scenario_list.append(scenario)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DeepAR uses Teacher Forcing\n",
                "params.training_method = utils.Hyperparams.TrainingMethod.TEACHER_FORCING"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for scenario in scenario_list:\n",
                "    nnts.torch.utils.seed_everything(scenario.seed)\n",
                "    df = df_orig.copy()\n",
                "    context_length = metadata.context_length + max(scenario.lag_seq)\n",
                "    split_data = nnts.pandas.split_test_train_last_horizon(\n",
                "        df, context_length, metadata.prediction_length\n",
                "    )\n",
                "    trn_dl, test_dl = nnts.data.create_trn_test_dataloaders(\n",
                "        split_data,\n",
                "        metadata,\n",
                "        scenario,\n",
                "        params,\n",
                "        nnts.torch.data.datasets.TorchTimeseriesLagsDataLoaderFactory(),\n",
                "    )\n",
                "    logger = nnts.loggers.LocalFileRun(\n",
                "        project=f\"{model_name}-{metadata.dataset}\",\n",
                "        name=scenario.name,\n",
                "        config={\n",
                "            **params.__dict__,\n",
                "            **metadata.__dict__,\n",
                "            **scenario.__dict__,\n",
                "        },\n",
                "        path=PATH,\n",
                "    )\n",
                "    net = nnts.torch.models.DeepAR(\n",
                "        nnts.torch.models.LinearModel,\n",
                "        params,\n",
                "        nnts.torch.data.preprocessing.masked_mean_abs_scaling,\n",
                "        1,\n",
                "        lag_seq=lag_seq,\n",
                "        scaled_features=scenario.scaled_covariates,\n",
                "    )\n",
                "    trner = trainers.TorchEpochTrainer(\n",
                "        nnts.trainers.TrainerState(), \n",
                "        net, \n",
                "        params, \n",
                "        metadata, \n",
                "        os.path.join(PATH, f\"{scenario.name}.pt\")\n",
                "    )\n",
                "    logger.configure(trner.events)\n",
                "\n",
                "    evaluator = trner.train(trn_dl)\n",
                "    y_hat, y = evaluator.evaluate(\n",
                "        test_dl, scenario.prediction_length, metadata.context_length\n",
                "    )\n",
                "    test_metrics = nnts.metrics.calc_metrics(\n",
                "        y, y_hat, nnts.metrics.calculate_seasonal_error(trn_dl, metadata)\n",
                "    )\n",
                "    logger.log(test_metrics)\n",
                "    print(test_metrics)\n",
                "    logger.finish()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_aggregator = nnts.utils.CSVFileAggregator(PATH, \"results\")\n",
                "results = csv_aggregator()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = pd.read_csv(f\"{PATH}/results.csv\")\n",
                "results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_list = deepar.add_y_hat(df, y_hat, scenario.prediction_length)\n",
                "sample_preds = nnts.experiments.plotting.plot(df_list, scenario.prediction_length)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 1], [0, 0, 0, 1, 0], [0, 0, 0, 1, 1], [0, 0, 1, 0, 0], [0, 0, 1, 0, 1], [0, 0, 1, 1, 0], [0, 0, 1, 1, 1], [0, 1, 0, 0, 0], [0, 1, 0, 0, 1], [0, 1, 0, 1, 0], [0, 1, 0, 1, 1], [0, 1, 1, 0, 0], [0, 1, 1, 0, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 1], [1, 0, 0, 1, 0], [1, 0, 0, 1, 1], [1, 0, 1, 0, 0], [1, 0, 1, 0, 1], [1, 0, 1, 1, 0], [1, 0, 1, 1, 1], [1, 1, 0, 0, 0], [1, 1, 0, 0, 1], [1, 1, 0, 1, 0], [1, 1, 0, 1, 1], [1, 1, 1, 0, 0], [1, 1, 1, 0, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 1]]\n"
                    ]
                }
            ],
            "source": [
                "def generate_one_hot_matrix(n):\n",
                "    # Total number of rows in the matrix\n",
                "    num_rows = 2**n\n",
                "\n",
                "    # Initialize the matrix\n",
                "    one_hot_matrix = []\n",
                "\n",
                "    # Generate each combination of binary values\n",
                "    for i in range(num_rows):\n",
                "        # Convert the number to its binary representation and fill with leading zeros\n",
                "        binary_representation = format(i, f\"0{n}b\")\n",
                "        # Convert the binary string to a list of integers\n",
                "        one_hot_row = [int(bit) for bit in binary_representation]\n",
                "        # Append the one-hot row to the matrix\n",
                "        one_hot_matrix.append(one_hot_row)\n",
                "\n",
                "    return one_hot_matrix\n",
                "\n",
                "\n",
                "# Example usage for n=5\n",
                "n = 5\n",
                "one_hot_matrix = generate_one_hot_matrix(n)\n",
                "\n",
                "# Print the first two rows to verify\n",
                "print(one_hot_matrix)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}