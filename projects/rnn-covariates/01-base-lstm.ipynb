{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List\n",
                "import seaborn as sns\n",
                "import os\n",
                "\n",
                "import nnts\n",
                "import nnts.data\n",
                "import nnts.experiments\n",
                "import nnts.hyperparams\n",
                "import nnts.torch.preprocessing as preprocessing\n",
                "import nnts.torch.trainers as trainers\n",
                "import nnts.torch.models\n",
                "import nnts.metrics\n",
                "import nnts.torch.datasets\n",
                "import nnts.loggers\n",
                "import nnts.pandas\n",
                "import covs \n",
                "\n",
                "sns.set()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = \"data\"\n",
                "model_name = \"base-lstm\"\n",
                "dataset_name = \"hospital\"\n",
                "results_path = \"nb-results\"\n",
                "metadata_path = os.path.join(data_path, f\"{model_name}-monash.json\")\n",
                "metadata = nnts.data.metadata.load(dataset_name, path=metadata_path)\n",
                "datafile_path = os.path.join(data_path, metadata.filename)\n",
                "PATH = os.path.join(results_path, model_name, metadata.dataset)\n",
                "\n",
                "df_orig, *_ = nnts.pandas.read_tsf(datafile_path)\n",
                "params = nnts.hyperparams.Hyperparams()\n",
                "splitter = nnts.pandas.LastHorizonSplitter()\n",
                "\n",
                "nnts.loggers.makedirs_if_not_exists(PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scenario_list: List[nnts.experiments.CovariateScenario] = []\n",
                "\n",
                "# Add the baseline scenarios\n",
                "for seed in [42, 43, 44, 45, 46]:\n",
                "    scenario_list.append(\n",
                "        nnts.experiments.CovariateScenario(metadata.prediction_length, error=0.0, covariates=0, seed=seed)\n",
                "    )\n",
                "## Models for full forecast horizon with covariates\n",
                "for covariates in [1, 2, 3]:\n",
                "    for error in covs.errors[metadata.dataset]:\n",
                "        scenario_list.append( \n",
                "            nnts.experiments.CovariateScenario(\n",
                "                metadata.prediction_length, error, covariates=covariates\n",
                "            )\n",
                "        )\n",
                "\n",
                "scenario_list.append( \n",
                "    nnts.experiments.CovariateScenario(\n",
                "        metadata.prediction_length, 0, covariates=3, skip=1\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for scenario in scenario_list[:1]:\n",
                "    nnts.torch.data.datasets.seed_everything(scenario.seed)\n",
                "    df, scenario = covs.prepare(df_orig.copy(), scenario)\n",
                "    split_data = splitter.split(df, metadata)\n",
                "    trn_dl, val_dl, test_dl = nnts.data.create_trn_val_test_dataloaders(\n",
                "        split_data,\n",
                "        metadata,\n",
                "        scenario,\n",
                "        params,\n",
                "        nnts.torch.data.TorchTimeseriesDataLoaderFactory(),\n",
                "    )\n",
                "    net = nnts.torch.models.BaseLSTM(\n",
                "        nnts.torch.models.LinearModel,\n",
                "        params,\n",
                "        preprocessing.masked_mean_abs_scaling,\n",
                "        scenario.covariates + 1,\n",
                "    )\n",
                "    logger = nnts.loggers.WandbRun(\n",
                "        project=f\"{model_name}-{metadata.dataset}\",\n",
                "        name=scenario.name,\n",
                "        config={\n",
                "            **params.__dict__,\n",
                "            **metadata.__dict__,\n",
                "            **scenario.__dict__,\n",
                "        },\n",
                "        path=PATH\n",
                "    )\n",
                "    trner = nnts.torch.models.trainers.TorchEpochTrainer(\n",
                "        nnts.trainers.TrainerState(),\n",
                "        net,\n",
                "        params,\n",
                "        metadata,\n",
                "        os.path.join(PATH, f\"{scenario.name}.pt\"),\n",
                "    )\n",
                "    logger.configure(trner.events)\n",
                "    evaluator = trner.train(trn_dl, val_dl)\n",
                "    handle = net.decoder.register_forward_hook(logger.log_activations)\n",
                "    y_hat, y = evaluator.evaluate(\n",
                "        test_dl, scenario.prediction_length, metadata.context_length, hooks=handle\n",
                "    )\n",
                "    handle.remove()\n",
                "    test_metrics = nnts.metrics.calc_metrics(\n",
                "        y, y_hat, nnts.metrics.calculate_seasonal_error(trn_dl, metadata)\n",
                "    )\n",
                "    logger.log(test_metrics)\n",
                "    logger.finish()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scenario = scenario_list[0]\n",
                "import torch\n",
                "import nnts.torch.models.trainers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nnts.torch.data.datasets.seed_everything(scenario.seed)\n",
                "df, scenario = covs.prepare(df_orig.copy(), scenario)\n",
                "splitter = nnts.pandas.LastHorizonSplitter()\n",
                "split_data = splitter.split(df, metadata)\n",
                "_, _, test_dl = nnts.data.create_trn_val_test_dataloaders(\n",
                "    split_data,\n",
                "    metadata,\n",
                "    scenario,\n",
                "    params,\n",
                "    nnts.torch.data.TorchTimeseriesDataLoaderFactory(),\n",
                ")\n",
                "net = covs.model_factory(model_name, params, scenario, metadata)\n",
                "best_state_dict = torch.load(f\"{PATH}/{scenario.name}.pt\")\n",
                "net.load_state_dict(best_state_dict)\n",
                "\n",
                "class ActivationVisualizer:\n",
                "    def __init__(self):\n",
                "        self.activations = []\n",
                "\n",
                "    def hook_handler(self, module, input, output):\n",
                "        input_0 = output[0][0]\n",
                "        self.activations.append(input_0[:, -1].detach().cpu().numpy())\n",
                "\n",
                "visualiser = ActivationVisualizer()\n",
                "handle = net.decoder.register_forward_hook(visualiser.hook_handler)\n",
                "net.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch = next(iter(test_dl))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    output = nnts.torch.models.trainers.validate(net, batch, scenario.prediction_length, metadata.context_length)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "handle.remove()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap(visualiser.activations, cmap=\"coolwarm\", linewidths=0.5)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch[\"X\"][0, : metadata.context_length, ...].cpu().numpy(), batch[\"X\"][\n",
                "    0, - scenario.prediction_length:, ...\n",
                "].cpu().numpy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output[0][0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap(output[0][0], cmap=\"coolwarm\", linewidths=0.5)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap([ v[-1:] for v in visualiser.activations], cmap=\"coolwarm\", linewidths=0.5)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap([v[-2:] for v in visualiser.activations], cmap=\"coolwarm\", linewidths=0.5)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nnts.pandas\n",
                "\n",
                "\n",
                "csv_aggregator = nnts.pandas.CSVFileAggregator(PATH, \"results\")\n",
                "results = csv_aggregator()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nnts.experiments\n",
                "import nnts.experiments.plotting\n",
                "\n",
                "\n",
                "df_list = covs.add_y_hat(df, y_hat, scenario.prediction_length)\n",
                "sample_preds = nnts.experiments.plotting.plot(df_list, scenario.prediction_length)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "univariate_results = results.loc[\n",
                "    (results[\"covariates\"] == 0)\n",
                "    & (results[\"prediction_length\"] == metadata.prediction_length),\n",
                "    [\"smape\", \"mape\", \"rmse\", \"mae\"],\n",
                "]\n",
                "\n",
                "univariate_results.mean(), univariate_results.std(), univariate_results.count()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cols = [\"dataset\", \"error\", \"pearson\", \"covariates\", \"prediction_length\", \"smape\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results.loc[\n",
                "    (results[\"covariates\"] > 0)\n",
                "    & (results[\"error\"].isin([0.000000, 0.4714285714285714, 1.65])),\n",
                "    cols,\n",
                "].sort_values(by=[\"covariates\", \"error\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sorted(results[\"error\"].unique().tolist())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
