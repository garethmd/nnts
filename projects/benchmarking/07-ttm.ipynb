{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T11:20:43.711984Z",
     "iopub.status.busy": "2024-09-10T11:20:43.711341Z",
     "iopub.status.idle": "2024-09-10T11:21:10.860211Z",
     "shell.execute_reply": "2024-09-10T11:21:10.858175Z",
     "shell.execute_reply.started": "2024-09-10T11:20:43.711915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-40210:t-7916067904:config.py:<module>:PyTorch version 2.4.0 available.\n",
      "INFO:p-40210:t-7916067904:config.py:<module>:Polars version 1.11.0 available.\n"
     ]
    }
   ],
   "source": [
    "import nnts\n",
    "import nnts.data\n",
    "import nnts.plotting\n",
    "import nnts.torch.preprocessing\n",
    "import nnts.torch.models\n",
    "import nnts.metrics\n",
    "import nnts.torch.datasets\n",
    "import nnts.loggers\n",
    "import nnts.datasets\n",
    "import nnts.torch.utils\n",
    "import nnts.torch.trainers\n",
    "import nnts.metrics\n",
    "import nnts.torch\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "import wandb\n",
    "from tsfm_public.models.tinytimemixer import TinyTimeMixerForPrediction\n",
    "from tsfm_public.toolkit.get_model import get_model\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T11:21:10.863715Z",
     "iopub.status.busy": "2024-09-10T11:21:10.862881Z",
     "iopub.status.idle": "2024-09-10T11:21:10.870720Z",
     "shell.execute_reply": "2024-09-10T11:21:10.869188Z",
     "shell.execute_reply.started": "2024-09-10T11:21:10.863666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\n",
    "    \"bitcoin\",\n",
    "    \"car_parts\",\n",
    "    \"cif_2016\",\n",
    "    \"covid_deaths\",\n",
    "    #\"dominick\",\n",
    "    #\"electricity_hourly\",\n",
    "    #\"electricity_weekly\",\n",
    "    \"fred_md\",\n",
    "    \"hospital\",\n",
    "    #\"kaggle_web_traffic\",\n",
    "    #\"kdd_cup\",\n",
    "    \"m1_monthly\",\n",
    "    \"m1_quarterly\",\n",
    "    \"m1_yearly\",\n",
    "    \"m3_monthly\",\n",
    "    \"m3_quarterly\",\n",
    "    \"m3_yearly\",\n",
    "    \"m4_daily\",\n",
    "    \"m4_hourly\",\n",
    "    \"m4_monthly\",\n",
    "    \"m4_quarterly\",\n",
    "    \"m4_weekly\",\n",
    "    \"m4_yearly\",#fails on date exceeding permitted range\n",
    "    \"nn5_daily\",\n",
    "    \"nn5_weekly\",\n",
    "    \"pedestrian_counts\",\n",
    "    \"rideshare\",\n",
    "    \"saugeen_river_flow\",\n",
    "    \"solar_10_minutes\",\n",
    "    \"solar_weekly\",\n",
    "    \"sunspot\",\n",
    "    \"temperature_rain\",\n",
    "    \"tourism_monthly\",\n",
    "    \"tourism_quarterly\",\n",
    "    \"tourism_yearly\",\n",
    "    \"traffic_hourly\",\n",
    "    \"traffic_weekly\",\n",
    "    \"us_births\",\n",
    "    \"vehicle_trips\",\n",
    "    \"weather\",\n",
    "    \"australian_electricity_demand\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTM Model path. The default model path is Granite-R2. Below, you can choose other TTM releases.\n",
    "model_name = \"ttm\"\n",
    "TTM_MODEL_PATH = \"ibm-granite/granite-timeseries-ttm-r2\"\n",
    "CONTEXT_LENGTH = 512\n",
    "PREDICTION_LENGTH = 96\n",
    "CONTEXT_LENGTH_ITEM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m4_hourly\n"
     ]
    }
   ],
   "source": [
    "dataset_name = DATASET_NAMES[13]\n",
    "print(dataset_name)\n",
    "df, metadata = nnts.datasets.load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_options = {\n",
    "    \"context_length\": metadata.context_length,\n",
    "    \"prediction_length\": metadata.prediction_length,\n",
    "    \"conts\": [],\n",
    "}\n",
    "trn_dl, test_dl = nnts.torch.utils.create_dataloaders(\n",
    "    df,\n",
    "    nnts.datasets.split_test_train_last_horizon,\n",
    "    metadata.context_length,\n",
    "    metadata.prediction_length,\n",
    "    Dataset=nnts.torch.datasets.TimeseriesDataset,\n",
    "    dataset_options=dataset_options,\n",
    "    Sampler=nnts.torch.datasets.TimeSeriesSampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:p-40210:t-7916067904:get_model.py:get_model:Loading model from: ibm-granite/granite-timeseries-ttm-r2\n",
      "WARNING:p-40210:t-7916067904:get_model.py:get_model:Requested `prediction_length` (48) is not exactly equal to any of the available TTM prediction lengths. Hence, TTM will forecast using the `prediction_filter_length` argument to provide the requested prediction length. Check the model card to know more about the supported context lengths and forecast/prediction lengths.\n",
      "INFO:p-40210:t-7916067904:get_model.py:get_model:Model loaded successfully from ibm-granite/granite-timeseries-ttm-r2, revision = 180-60-ft-l1-r2.1.\n",
      "INFO:p-40210:t-7916067904:get_model.py:get_model:[TTM] context_length = 180, prediction_length = 60\n"
     ]
    }
   ],
   "source": [
    "zeroshot_model = get_model(\n",
    "    TTM_MODEL_PATH,\n",
    "    context_length=metadata.context_length,\n",
    "    prediction_length=metadata.prediction_length,\n",
    "    freq_prefix_tuning=False,\n",
    "    freq=None,\n",
    "    prefer_l1_loss=True,\n",
    "    prefer_longer_context=True,\n",
    "    force_return='zeropad',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_model.config.context_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = tempfile.mkdtemp()\n",
    "SEED = 42\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(filename='m4_hourly_dataset.tsf', dataset='m4_hourly', context_length=210, prediction_length=48, freq='1H', seasonality=24, url='https://zenodo.org/records/4656589/files/m4_hourly_dataset.zip', context_lengths=[210, 96, 60], multivariate=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_trainer = Trainer(\n",
    "    model=zeroshot_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=temp_dir,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        seed=SEED,\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(filename='m4_hourly_dataset.tsf', dataset='m4_hourly', context_length=210, prediction_length=48, freq='1H', seasonality=24, url='https://zenodo.org/records/4656589/files/m4_hourly_dataset.zip', context_lengths=[210, 96, 60], multivariate=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FREQUENCY_MAPPING = {\n",
    "    \"oov\": 0,\n",
    "    \"min\": 1,  # minutely\n",
    "    \"2min\": 2,\n",
    "    \"5min\": 3,\n",
    "    \"10min\": 4,\n",
    "    \"15min\": 5,\n",
    "    \"30min\": 6,\n",
    "    \"h\": 7,  # hourly\n",
    "    \"1H\": 7,  # hourly, for compatibility\n",
    "    \"d\": 8,  # daily, for compatibility\n",
    "    \"D\": 8,  # daily\n",
    "    \"W\": 9,  # weekly\n",
    "}\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, ds, metadata):\n",
    "        self.ds = ds\n",
    "        self.metadata = metadata\n",
    "        self.fixed_context_length = 512\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        padded_data = self.ds[idx]\n",
    "        past_values = padded_data.data[:self.metadata.context_length]\n",
    "        future_values = padded_data.data[self.metadata.context_length :]\n",
    "        zero_padded_data = torch.zeros(self.fixed_context_length, 1)\n",
    "        zero_padded_data[-past_values.shape[0] :] = past_values\n",
    "        past_observed_mask = torch.zeros(self.fixed_context_length, 1)\n",
    "        past_observed_mask[-past_values.shape[0] :] = 1\n",
    "\n",
    "        return {\n",
    "            \"past_values\": zero_padded_data,\n",
    "            \"future_values\": future_values,\n",
    "            \"past_observed_mask\": past_observed_mask.bool(),\n",
    "            \"freq_token\": torch.tensor(\n",
    "                DEFAULT_FREQUENCY_MAPPING.get(self.metadata.freq, 0), dtype=torch.int32\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "\n",
    "class TruncatedDataset:\n",
    "    def __init__(self, ds, metadata, model_context_length):\n",
    "        self.ds = ds\n",
    "        self.metadata = metadata\n",
    "        self.model_context_length = model_context_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        padded_data = self.ds[idx]\n",
    "        past_values = padded_data.data[\n",
    "            -self.model_context_length\n",
    "            - self.metadata.prediction_length : -self.metadata.prediction_length\n",
    "        ]\n",
    "        future_values = padded_data.data[-self.metadata.prediction_length :]\n",
    "        past_observed_mask = torch.ones(self.model_context_length, 1)\n",
    "\n",
    "        return {\n",
    "            \"past_values\": past_values,\n",
    "            \"future_values\": future_values,\n",
    "            \"past_observed_mask\": past_observed_mask.bool(),\n",
    "            \"freq_token\": torch.tensor(\n",
    "                DEFAULT_FREQUENCY_MAPPING.get(self.metadata.freq, 0), dtype=torch.int32\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zeroshot_model.config.context_length < metadata.context_length:\n",
    "    test_data = TruncatedDataset(test_dl.dataset, metadata, zeroshot_model.config.context_length)\n",
    "else:\n",
    "    test_data = Dataset(test_dl.dataset, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][\"future_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 2104972.25, 'abs_error': 5907565.0, 'abs_target_sum': 145558864.0, 'abs_target_mean': 7324.822265625, 'seasonal_error': 336.9046936035156, 'mean_mase': 2.3399574756622314, 'mean_mape': 0.13688777387142181, 'mean_smape': 0.1268552839756012, 'mean_msmape': 0.1267193853855133, 'mean_mae': 297.28082275390625, 'mean_rmse': 358.534423828125, 'median_mase': 1.2051705121994019, 'median_smape': 0.0616854764521122, 'median_msmape': 0.0616719089448452, 'median_mae': 14.963363647460938, 'median_rmse': 21.463424682617188}\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = zeroshot_trainer.predict(test_data)\n",
    "y = test_dl.dataset.X[:, -metadata.prediction_length :]\n",
    "y_hat = torch.tensor(predictions_dict[0][0])\n",
    "seasonal_error = nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)\n",
    "test_metrics = nnts.metrics.calc_metrics(\n",
    "    y_hat,\n",
    "    y,\n",
    "    seasonal_error,\n",
    ")\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfm_public import (\n",
    "    TimeSeriesPreprocessor,\n",
    "    TrackingCallback,\n",
    "    count_parameters,\n",
    "    get_datasets,\n",
    ")\n",
    "\n",
    "TARGET_DATASET = \"etth1\"\n",
    "dataset_path = \"data/ETTh1.csv\"\n",
    "timestamp_column = \"date\"\n",
    "id_columns = []  # mention the ids that uniquely identify a time-series.\n",
    "\n",
    "target_columns = [\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
    "split_config = {\n",
    "    \"train\": [0, 8640],\n",
    "    \"valid\": [8640, 11520],\n",
    "    \"test\": [\n",
    "        11520,\n",
    "        14400,\n",
    "    ],\n",
    "}\n",
    "# Understanding the split config -- slides\n",
    "\n",
    "data = pd.read_csv(\n",
    "    dataset_path,\n",
    "    parse_dates=[timestamp_column],\n",
    ")\n",
    "\n",
    "column_specifiers = {\n",
    "    \"timestamp_column\": timestamp_column,\n",
    "    \"id_columns\": id_columns,\n",
    "    \"target_columns\": target_columns,\n",
    "    \"control_columns\": [],\n",
    "}\n",
    "context_length=512\n",
    "forecast_length=96\n",
    "tsp = TimeSeriesPreprocessor(\n",
    "    **column_specifiers,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_length,\n",
    "    scaling=True,\n",
    "    encode_categorical=False,\n",
    "    scaler_type=\"standard\",\n",
    ")\n",
    "\n",
    "dset_train, dset_valid, dset_test = get_datasets(\n",
    "    tsp,\n",
    "    data,\n",
    "    split_config,\n",
    "    use_frequency_token=zeroshot_model.config.resolution_prefix_tuning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 7])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_test[0][\"past_observed_mask\"].shape"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nnts-uwGNJDPB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
