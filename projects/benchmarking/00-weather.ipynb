{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "import torch.optim\n",
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "import nnts\n",
                "import nnts.data\n",
                "from nnts import utils\n",
                "import nnts.torch.models\n",
                "import nnts.torch.trainers\n",
                "import nnts.metrics\n",
                "import nnts.torch.datasets\n",
                "import nnts.torch.utils\n",
                "import nnts.loggers\n",
                "from nnts import datasets\n",
                "torch.set_printoptions(precision=8, sci_mode=False)\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = \"data\"\n",
                "model_name = \"\"\n",
                "dataset_name = \"weather\"\n",
                "results_path = \"nb-results\"\n",
                "metadata_path = \"informer.json\"\n",
                "\n",
                "metadata = datasets.load_metadata(dataset_name, path=metadata_path)\n",
                "datafile_path = os.path.join(data_path, metadata.filename)\n",
                "PATH = os.path.join(results_path, model_name, metadata.dataset)\n",
                "df = pd.read_csv(datafile_path)\n",
                "utils.makedirs_if_not_exists(PATH)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = utils.Hyperparams(\n",
                "    optimizer=torch.optim.Adam,\n",
                "    loss_fn=torch.nn.L1Loss(),\n",
                "    batch_size=32,\n",
                "    batches_per_epoch=50,\n",
                "    training_method=utils.TrainingMethod.DMS,\n",
                "    model_file_path=\"logs\",\n",
                "    epochs=100,\n",
                "    scheduler=utils.Scheduler.REDUCE_LR_ON_PLATEAU,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.rename({\"WetBulbCelsius\": \"y\", \"date\": \"ds\"}, axis=\"columns\")\n",
                "df[\"unique_id\"] = \"T1\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "# split lengths as per informer\n",
                "trn_length = int(24 * 365.25 * 2)\n",
                "val_test_length = int(24 * 365.25 * (10 / 12))\n",
                "split_data = datasets.split_test_val_train(\n",
                "    df, trn_length, val_test_length, val_test_length\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/garethdavies/Development/workspaces/nnts/nnts/torch/preprocessing.py:63: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  data[numeric_cols] = (numeric_data - self.mean) / self.std\n"
                    ]
                }
            ],
            "source": [
                "nnts.torch.utils.seed_everything(42)\n",
                "dataset_options = {\n",
                "    \"context_length\": metadata.context_length,\n",
                "    \"prediction_length\": metadata.prediction_length,\n",
                "    \"conts\": [],\n",
                "}\n",
                "\n",
                "trn_dl, val_dl, test_dl = nnts.torch.utils.create_dataloaders_from_split_data(\n",
                "    split_data,\n",
                "    Dataset=nnts.torch.datasets.TimeseriesDataset,\n",
                "    dataset_options=dataset_options,\n",
                "    Sampler=nnts.torch.datasets.TimeSeriesSampler,\n",
                "    batch_size=params.batch_size,\n",
                "    transforms = [nnts.torch.preprocessing.StandardScaler()]\n",
                ")\n",
                "\n",
                "net = nnts.torch.models.DLinear(metadata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DLinear(\n",
                        "  (decompsition): series_decomp(\n",
                        "    (moving_avg): moving_avg(\n",
                        "      (avg): AvgPool1d(kernel_size=(25,), stride=(1,), padding=(0,))\n",
                        "    )\n",
                        "  )\n",
                        "  (Linear_Seasonal): ModuleList(\n",
                        "    (0): Linear(in_features=505, out_features=168, bias=True)\n",
                        "  )\n",
                        "  (Linear_Trend): ModuleList(\n",
                        "    (0): Linear(in_features=505, out_features=168, bias=True)\n",
                        "  )\n",
                        "  (Linear_Decoder): ModuleList(\n",
                        "    (0): Linear(in_features=505, out_features=168, bias=True)\n",
                        "  )\n",
                        ")\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n",
                        "saving model to logs/best_model.pt\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'mse': 0.21180547773838043,\n",
                            " 'abs_error': 368254.8125,\n",
                            " 'abs_target_sum': 897140.6875,\n",
                            " 'abs_target_mean': 0.8050841093063354,\n",
                            " 'seasonal_error': 0.30613401532173157,\n",
                            " 'mean_mase': 1.0794873237609863,\n",
                            " 'mean_mape': 1.5616284608840942,\n",
                            " 'mean_smape': 0.7036300897598267,\n",
                            " 'mean_msmape': 0.5347234010696411,\n",
                            " 'mean_mae': 0.3304677903652191,\n",
                            " 'mean_rmse': 0.4061824083328247,\n",
                            " 'median_mase': 0.9741610884666443,\n",
                            " 'median_smape': 0.655884861946106,\n",
                            " 'median_msmape': 0.4708513617515564,\n",
                            " 'median_mae': 0.2982238531112671,\n",
                            " 'median_rmse': 0.37352558970451355}"
                        ]
                    },
                    "execution_count": 56,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "trner = nnts.torch.trainers.ValidationTorchEpochTrainer(net, params, metadata)\n",
                "evaluator = trner.train(trn_dl, val_dl)\n",
                "y_hat, y = evaluator.evaluate(\n",
                "    test_dl, metadata.prediction_length, metadata.context_length\n",
                ")\n",
                "\n",
                "test_metrics = nnts.metrics.calc_metrics(\n",
                "    y_hat, y, nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)\n",
                ")\n",
                "test_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for scenario in scenario_list[:1]:\n",
                "    nnts.torch.utils.seed_everything(scenario.seed)\n",
                "    df, scenario = prepare(df_orig.copy(), scenario)\n",
                "    split_data = splitter.split(\n",
                "        df, trn_length, val_test_length, val_test_length\n",
                "    )\n",
                "    trn_dl, val_dl, test_dl = nnts.data.create_trn_val_test_dataloaders(\n",
                "        split_data,\n",
                "        metadata,\n",
                "        scenario,\n",
                "        params,\n",
                "        nnts.torch.data.TorchTimeseriesDataLoaderFactory(),\n",
                "        [nnts.torch.data.preprocessing.StandardScaler()],\n",
                "    )\n",
                "    logger = nnts.loggers.WandbRun(\n",
                "        project=f\"{model_name}-{metadata.dataset}\",\n",
                "        name=scenario.name,\n",
                "        config={\n",
                "            **params.__dict__,\n",
                "            **metadata.__dict__,\n",
                "            **scenario.__dict__,\n",
                "        },\n",
                "        path=PATH,\n",
                "    )\n",
                "\n",
                "    net = nnts.torch.models.SegLSTM(\n",
                "        nnts.torch.models.LinearModel,\n",
                "        params,\n",
                "        nnts.torch.data.preprocessing.masked_mean_abs_scaling,\n",
                "        scenario.covariates + 1,\n",
                "        24\n",
                "    )\n",
                "    trner = trainers.TorchEpochTrainer(\n",
                "        nnts.trainers.TrainerState(), \n",
                "        net, \n",
                "        params, \n",
                "        metadata, \n",
                "        os.path.join(PATH, f\"{scenario.name}.pt\"),\n",
                "    )\n",
                "    logger.configure(trner.events)\n",
                "\n",
                "    evaluator = trner.train(trn_dl, val_dl)\n",
                "    handle = net.decoder.register_forward_hook(logger.log_activations)\n",
                "    y_hat, y = evaluator.evaluate(\n",
                "        test_dl, scenario.prediction_length, metadata.context_length, hooks=handle\n",
                "    )\n",
                "    handle.remove()\n",
                "    test_metrics = nnts.metrics.calc_metrics(\n",
                "        y_hat, y, nnts.metrics.calculate_seasonal_error(trn_dl, metadata.seasonality)\n",
                "    )\n",
                "    logger.log(test_metrics)\n",
                "    logger.finish()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_hat.shape, y.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nnts.metrics.calc_metrics(y_hat, y, trn_dl, metadata)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nnts.metrics.calc_metrics(y_hat[:, :1, :], y[:, :1, :], nnts.metrics.calculate_seasonal_error(trn_dl, metadata))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_results(y_hat, y, name):\n",
                "    torch.save(y_hat, f\"{PATH}/{name}_y_hat.pt\")\n",
                "    torch.save(y, f\"{PATH}/{name}_y.pt\")\n",
                "save_results(y_hat, y, scenario.name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "covariate_name = f\"cov-1-pearsn-0.68-pl-{str(scenario.prediction_length)}-seed-{scenario.seed}\"\n",
                "covariate_y_hat = torch.load(f\"{PATH}/{covariate_name}_y_hat.pt\")\n",
                "covariate_y = torch.load(f\"{PATH}/{covariate_name}_y.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_forecast_horizon_metrics(y_hat, y, metadata, metric=\"mae\"):\n",
                "    forecast_horizon_metrics = []\n",
                "    for i in range(1, metadata.prediction_length):\n",
                "        metrics = nnts.metrics.calc_metrics(y[:, :i, :], y_hat[:, :i, :], metadata.freq, metadata.seasonality)\n",
                "        forecast_horizon_metrics.append(metrics[metric])\n",
                "    return forecast_horizon_metrics\n",
                "\n",
                "forecast_horizon_metrics = calculate_forecast_horizon_metrics(y_hat, y, metadata, \"mae\")\n",
                "covariate_forecast_horizon_metrics = calculate_forecast_horizon_metrics(covariate_y_hat, covariate_y, metadata, \"mae\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "sns.set()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(forecast_horizon_metrics, label='univariate')\n",
                "plt.plot(covariate_forecast_horizon_metrics, label='covariate (0.68)')\n",
                "plt.xlabel(\"Forecast Horizon\")\n",
                "plt.ylabel(\"Error (MAE)\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_aggregator = nnts.datasets.CSVFileAggregator(PATH, \"results\")\n",
                "results = csv_aggregator()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.tail(metadata.prediction_length*50)['y'].plot()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_hat_last = y_hat[:, :1, ...]\n",
                "y_last = y[:, :1, ...]\n",
                "df_test = df.tail(y_hat_last.shape[0])\n",
                "df_test[\"y_check\"] = y_last.squeeze()\n",
                "df_test[\"y_hat\"] = y_hat_last.squeeze()\n",
                "df_test[[\"y\", \"y_check\", \"y_hat\"]]\n",
                "df_test.set_index(\"ds\")[[\"y_check\", \"y_hat\"]].iloc[4500:4500+336].plot(figsize=(20, 10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_metrics = nnts.metrics.calc_metrics(y_last, y_hat_last, metadata.freq, metadata.seasonality)\n",
                "test_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
